{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discrete Choice Analysis: micro-econometrics and machine learning approaches\n",
    "\n",
    "## `Lab session 2: Hybrid models`\n",
    "\n",
    "**Delft University of Technology**<br>\n",
    "**February 2024**<br>\n",
    "**Instructor:** Sander van Cranenburgh <br>\n",
    "**TAs:**  Gabriel Nova <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Instructions`\n",
    "\n",
    "**Lab sessions aim to:**<br>\n",
    "* Show and reinforce how models and ideas presented in class are put to practice.<br>\n",
    "* Help you gather hands-on machine learning skills.<br>\n",
    "\n",
    "**Lab sessions are:**<br>\n",
    "* Learning environments where you work with Jupyter notebooks and where you can get support from TAs and fellow students.<br> \n",
    "* Not graded and do not have to be submitted. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Option 1: Local environment**<br>\n",
    "Uncomment the following cell if you are running this notebook on your local environment, to install all dependencies on your Python version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Option 2: Google Colab**<br>\n",
    "Uncomment the following cell if you are running this notebook on Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!git clone https://github.com/DCM-ML-course-TRAIL/DCM_ML_TRAIL_2024\n",
    "#!pip install -r DCM_ML_TRAIL_2024/requirements_colab.txt\n",
    "#!mv \"/content/DCM_ML_TRAIL_2024/Lab sessions/data\" /content/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Application: Modelling neighbourhood choices` <br>\n",
    "In this lab session, we will analyse neighbourhood location choice behaviour. Understanding people's preferences over neighbourhood characteristics is crucial for city planners when they (re)develop neighbourhoods or devise policies to tackle e.g. residential segregation. During this lab session, you will apply discrete choice models to uncover people's preferences over attributes, such as the distance to the city centre and the share of foreigners in their neighbourhood. Also, you will explore whether preferences interact with covariates such as age, gender, home ownership, car ownership and urbanisation level. While doing so, you will test various utility specifications and interpret the modelling outcomes of discrete choice models.\n",
    "\n",
    "For this study, we use data from a Stated Choice (SC) experiment, which was conducted between 2017 and 2018 in four European cities: Hanover, Mainz, Bern, and Zurich.\n",
    "\n",
    "**`Learning objectives lab session 02`**\n",
    "After completing the following lab session you will be able to:\n",
    "* Train a MultiLayer Perceptron on choice data\n",
    "* Train a hybrid choice model, using PyTorch\n",
    "* Strike a balance between behavioural rigour and model fit\n",
    "* Reflect on the strength and weaknesses of both data and theory-driven modelling approaches\n",
    "\n",
    "**`This lab consists of 4 parts and has 5 exercises`**\n",
    "\n",
    "**Part 1**: Data preparation\n",
    "\n",
    "**Part 2**: The linear-additive RUM-MNL model\n",
    "- Excerise 1: \"Willigness to pay for grocery stores\"\n",
    "\n",
    "**Part 3**: The MultiLayer Perceptron\n",
    "- Excerise 2: \"Training the MLP model\"\n",
    "- Excerise 3: \"Adding the socio-demographic features\"\n",
    "\n",
    "**Part 4**: The L-MNL model\n",
    "- Excerise 4: \"Feature MLP\"\n",
    "- Excerise 5: \"Forescasting using L-MNL model\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Import packages`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required Python packages and modules\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from os import getcwd\n",
    "from pathlib import Path\n",
    "\n",
    "# Biogeme\n",
    "import biogeme.database as db\n",
    "import biogeme.biogeme as bio\n",
    "from biogeme import models\n",
    "from biogeme.expressions import Beta, Variable, log\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Preparing your data set**\n",
    "To prepare the data set, we will:<br>\n",
    "    1.1 **Load** the data set<br>\n",
    "    1.2 **Clean** and **prepare** the data set<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " `i. Set up the workspace and load the database`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create that path to the data file\n",
    "data_path = Path(f'data/choice_data.dat')\n",
    "\n",
    "# Load mode choice data into a pandas DataFrame\n",
    "df = pd.read_csv(data_path, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9720, 32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load mode choice data into a pandas DataFrame\n",
    "df = pd.read_csv(data_path,sep = '\\t')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Description of variables**<br>\n",
    "\n",
    "The number concatenated to the variable refers to the alternative. Hence, `STORES1` is the column containing the attribute levels of alternative 1 for attribute STORES.<br>\n",
    "\n",
    "| Variable       | Description                                                    | Type/Levels |\n",
    "|-------------|----------------------------------------------------------------|--------------|\n",
    "| `ID`        | This is the ID number of the respondent                         | Integer      |\n",
    "| `TASK_ID`   | This is the number of the respondent's task of choice           | Integer      |\n",
    "| `STORES`    | Distance to grocery store in walking minutes                    | 2 Min., 5 Min., 10 Min., 15 Min.     |\n",
    "| `TRANSPORT` | Distance to public transportation in walking minutes            | 2 Min., 5 Min., 10 Min., 15 Min.      |\n",
    "| `CITY`      | Distance to city centre in km                                   | Below 1 km, 1 to 2 km, 3 to 4 km, over 4 km      |\n",
    "| `NOISE`     | Street traffic noise                                            | 1 = None, 2 = Little, 3 = Meduim, 4 = High      |\n",
    "| `GREEN`     | Green areas in residential area                                 | 1 = None, 2 = Few, 3 = Some, 4 = Many       |\n",
    "| `FOREIGN`   | Share of foreigners in residential areas                        | 0.10, 0.20, 0.30, 0.40     |\n",
    "| `CHOICE`    | Indicates the choice.                                           | Integer  |\n",
    "| `RESPCITY`  | Indicates the city. 1 = Mainz, 2 = Hanover, 3 = Bern, 4 = Zurich| Categorical  |\n",
    "| `WOMAN`     | Indicates 1 if woman and 0 otherwise                            | Binary       |\n",
    "| `AGE`       | Age in years                                                    | Integer      |\n",
    "| `ENVCONC`   | Environmental concern from 1 to 5, with 5 being the highest degree of concern | Ordinal |\n",
    "| `EDUYEARS`  | Number of years in education                                    | Numeric      |\n",
    "| `RESPFOREIGN`| 1 if the respondent is a foreigner, 0 otherwise                | Binary       |\n",
    "| `HOMEOWNER` | Indicates 1 if the respondent is a home owner and 0 otherwise   | Binary       |\n",
    "| `CAROWNER`  | Indicates 1 if the respondent is a car owner and 0 otherwise    | Binary       |\n",
    "| `JOB`       | 1 if the respondent is working, 0 otherwise                     | Binary       |\n",
    "| `NONWESTERN`| 1 if the respondent is non-western, 0 otherwise                 | Binary       |\n",
    "| `WESTERN`   | 1 if the respondent is western, 0 otherwise                     | Binary       |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.2 Inspect, clean and prepare the data**<br>\n",
    "Before starting to analyse your data, make sure you understand what features are in your data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TASK_ID</th>\n",
       "      <th>STORES1</th>\n",
       "      <th>TRANSPORT1</th>\n",
       "      <th>CITY1</th>\n",
       "      <th>NOISE1</th>\n",
       "      <th>GREEN1</th>\n",
       "      <th>FOREIGN1</th>\n",
       "      <th>STORES2</th>\n",
       "      <th>TRANSPORT2</th>\n",
       "      <th>...</th>\n",
       "      <th>WOMAN</th>\n",
       "      <th>AGE</th>\n",
       "      <th>ENVCONC</th>\n",
       "      <th>EDUYEARS</th>\n",
       "      <th>RESPFOREIGN</th>\n",
       "      <th>HOMEOWNER</th>\n",
       "      <th>CAROWNER</th>\n",
       "      <th>JOB</th>\n",
       "      <th>NONWESTERN</th>\n",
       "      <th>WESTERN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9720.000000</td>\n",
       "      <td>9720.000000</td>\n",
       "      <td>9720.000000</td>\n",
       "      <td>9720.000000</td>\n",
       "      <td>9720.000000</td>\n",
       "      <td>9720.000000</td>\n",
       "      <td>9720.000000</td>\n",
       "      <td>9720.000000</td>\n",
       "      <td>9720.000000</td>\n",
       "      <td>9720.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>9720.000000</td>\n",
       "      <td>9720.000000</td>\n",
       "      <td>9720.000000</td>\n",
       "      <td>9720.000000</td>\n",
       "      <td>9720.000000</td>\n",
       "      <td>9720.00000</td>\n",
       "      <td>9720.000000</td>\n",
       "      <td>9720.000000</td>\n",
       "      <td>9720.000000</td>\n",
       "      <td>9720.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4936.131276</td>\n",
       "      <td>19743.025103</td>\n",
       "      <td>7.972634</td>\n",
       "      <td>7.997737</td>\n",
       "      <td>3.006996</td>\n",
       "      <td>2.495576</td>\n",
       "      <td>2.502984</td>\n",
       "      <td>0.249095</td>\n",
       "      <td>8.007407</td>\n",
       "      <td>7.937449</td>\n",
       "      <td>...</td>\n",
       "      <td>206.288477</td>\n",
       "      <td>702.665432</td>\n",
       "      <td>1937.691427</td>\n",
       "      <td>3800.628807</td>\n",
       "      <td>823.193827</td>\n",
       "      <td>41.37572</td>\n",
       "      <td>617.895885</td>\n",
       "      <td>1564.486831</td>\n",
       "      <td>41.310700</td>\n",
       "      <td>41.247737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2791.776351</td>\n",
       "      <td>11167.105459</td>\n",
       "      <td>4.943312</td>\n",
       "      <td>4.969792</td>\n",
       "      <td>1.581009</td>\n",
       "      <td>1.121941</td>\n",
       "      <td>1.110794</td>\n",
       "      <td>0.111187</td>\n",
       "      <td>4.937217</td>\n",
       "      <td>4.933491</td>\n",
       "      <td>...</td>\n",
       "      <td>4531.586747</td>\n",
       "      <td>8084.394737</td>\n",
       "      <td>13772.314585</td>\n",
       "      <td>19083.662381</td>\n",
       "      <td>9035.133163</td>\n",
       "      <td>2028.26417</td>\n",
       "      <td>7832.731177</td>\n",
       "      <td>12407.404755</td>\n",
       "      <td>2028.265479</td>\n",
       "      <td>2028.266745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2541.000000</td>\n",
       "      <td>10162.750000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>3.166667</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5003.500000</td>\n",
       "      <td>20012.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>16.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7305.000000</td>\n",
       "      <td>29218.250000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9825.000000</td>\n",
       "      <td>39300.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>99999.00000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                ID       TASK_ID      STORES1   TRANSPORT1        CITY1  \\\n",
       "count  9720.000000   9720.000000  9720.000000  9720.000000  9720.000000   \n",
       "mean   4936.131276  19743.025103     7.972634     7.997737     3.006996   \n",
       "std    2791.776351  11167.105459     4.943312     4.969792     1.581009   \n",
       "min       2.000000      5.000000     2.000000     2.000000     1.000000   \n",
       "25%    2541.000000  10162.750000     2.000000     2.000000     2.000000   \n",
       "50%    5003.500000  20012.500000     5.000000     5.000000     4.000000   \n",
       "75%    7305.000000  29218.250000    10.000000    15.000000     5.000000   \n",
       "max    9825.000000  39300.000000    15.000000    15.000000     5.000000   \n",
       "\n",
       "            NOISE1       GREEN1     FOREIGN1      STORES2   TRANSPORT2  ...  \\\n",
       "count  9720.000000  9720.000000  9720.000000  9720.000000  9720.000000  ...   \n",
       "mean      2.495576     2.502984     0.249095     8.007407     7.937449  ...   \n",
       "std       1.121941     1.110794     0.111187     4.937217     4.933491  ...   \n",
       "min       1.000000     1.000000     0.100000     2.000000     2.000000  ...   \n",
       "25%       1.000000     2.000000     0.200000     5.000000     2.000000  ...   \n",
       "50%       3.000000     3.000000     0.200000    10.000000     5.000000  ...   \n",
       "75%       3.000000     3.000000     0.300000    10.000000    10.000000  ...   \n",
       "max       4.000000     4.000000     0.400000    15.000000    15.000000  ...   \n",
       "\n",
       "              WOMAN           AGE       ENVCONC      EDUYEARS   RESPFOREIGN  \\\n",
       "count   9720.000000   9720.000000   9720.000000   9720.000000   9720.000000   \n",
       "mean     206.288477    702.665432   1937.691427   3800.628807    823.193827   \n",
       "std     4531.586747   8084.394737  13772.314585  19083.662381   9035.133163   \n",
       "min        0.000000     18.000000      1.000000      8.000000      0.000000   \n",
       "25%        0.000000     34.000000      3.166667     13.000000      0.000000   \n",
       "50%        1.000000     44.000000      3.666667     16.500000      0.000000   \n",
       "75%        1.000000     56.000000      4.166667     18.000000      0.000000   \n",
       "max    99999.000000  99999.000000  99999.000000  99999.000000  99999.000000   \n",
       "\n",
       "         HOMEOWNER      CAROWNER           JOB    NONWESTERN       WESTERN  \n",
       "count   9720.00000   9720.000000   9720.000000   9720.000000   9720.000000  \n",
       "mean      41.37572    617.895885   1564.486831     41.310700     41.247737  \n",
       "std     2028.26417   7832.731177  12407.404755   2028.265479   2028.266745  \n",
       "min        0.00000      0.000000      0.000000      0.000000      0.000000  \n",
       "25%        0.00000      0.000000      0.000000      0.000000      0.000000  \n",
       "50%        0.00000      1.000000      1.000000      0.000000      0.000000  \n",
       "75%        0.00000      1.000000      1.000000      0.000000      0.000000  \n",
       "max    99999.00000  99999.000000  99999.000000  99999.000000  99999.000000  \n",
       "\n",
       "[8 rows x 32 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table above provides important insights about the variables in our data set. The mean and standard deviation (std) of some variables are suspiciously high. This suggests possible problems in the data set. For example, the mean values of `WOMAN`, `AGE`, `EDUYEARS` are significantly higher than expected based on the table with the coding of the variables. This could indicate issues in the data set, the presence of outliers, or missing values. From the table above, it can be seen that the number `99999` does not agree with the usual values for variables such as `WOMEN`, `AGE` and `others`.<br>\n",
    "\n",
    "This suggests that the value `99999` has been used to represent `missing values` in the data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Data set for estimation`**<br>\n",
    "\n",
    "Given our objective to investigate the impact of age, gender, home ownership, car ownership and urbanisation, we need to handle the rows of the data with missing values in these columns. Fortunately, the proportion of missing data in these columns is relatively small. Therefore, a fair strategy in this case to simply eliminate the data rows with missing values in these columns. Another strategy could have been imputing the median values. However, this strategy also has its disadvantages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TASK_ID</th>\n",
       "      <th>STORES1</th>\n",
       "      <th>TRANSPORT1</th>\n",
       "      <th>CITY1</th>\n",
       "      <th>NOISE1</th>\n",
       "      <th>GREEN1</th>\n",
       "      <th>FOREIGN1</th>\n",
       "      <th>STORES2</th>\n",
       "      <th>TRANSPORT2</th>\n",
       "      <th>...</th>\n",
       "      <th>FOREIGN3</th>\n",
       "      <th>AGE</th>\n",
       "      <th>WOMAN</th>\n",
       "      <th>HOMEOWNER</th>\n",
       "      <th>CAROWNER</th>\n",
       "      <th>RESPCITY</th>\n",
       "      <th>JOB</th>\n",
       "      <th>EDUYEARS</th>\n",
       "      <th>ENVCONC</th>\n",
       "      <th>CHOICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9032.000000</td>\n",
       "      <td>9032.000000</td>\n",
       "      <td>9032.000000</td>\n",
       "      <td>9032.000000</td>\n",
       "      <td>9032.000000</td>\n",
       "      <td>9032.000000</td>\n",
       "      <td>9032.000000</td>\n",
       "      <td>9032.000000</td>\n",
       "      <td>9032.000000</td>\n",
       "      <td>9032.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>9032.000000</td>\n",
       "      <td>9032.000000</td>\n",
       "      <td>9032.000000</td>\n",
       "      <td>9032.000000</td>\n",
       "      <td>9032.000000</td>\n",
       "      <td>9032.000000</td>\n",
       "      <td>9032.000000</td>\n",
       "      <td>9032.000000</td>\n",
       "      <td>9032.000000</td>\n",
       "      <td>9032.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4938.589460</td>\n",
       "      <td>19752.857839</td>\n",
       "      <td>7.981842</td>\n",
       "      <td>7.978299</td>\n",
       "      <td>3.007418</td>\n",
       "      <td>2.496678</td>\n",
       "      <td>2.503432</td>\n",
       "      <td>0.249302</td>\n",
       "      <td>8.002214</td>\n",
       "      <td>7.948406</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250498</td>\n",
       "      <td>44.530115</td>\n",
       "      <td>0.532329</td>\n",
       "      <td>0.224092</td>\n",
       "      <td>0.624004</td>\n",
       "      <td>2.614703</td>\n",
       "      <td>0.735607</td>\n",
       "      <td>15.254650</td>\n",
       "      <td>3.625000</td>\n",
       "      <td>1.958924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2798.272394</td>\n",
       "      <td>11193.089632</td>\n",
       "      <td>4.945691</td>\n",
       "      <td>4.966099</td>\n",
       "      <td>1.581524</td>\n",
       "      <td>1.121651</td>\n",
       "      <td>1.112332</td>\n",
       "      <td>0.111112</td>\n",
       "      <td>4.939272</td>\n",
       "      <td>4.931868</td>\n",
       "      <td>...</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>13.463328</td>\n",
       "      <td>0.498981</td>\n",
       "      <td>0.417006</td>\n",
       "      <td>0.484406</td>\n",
       "      <td>1.108207</td>\n",
       "      <td>0.441034</td>\n",
       "      <td>2.702097</td>\n",
       "      <td>0.771467</td>\n",
       "      <td>0.813718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2535.000000</td>\n",
       "      <td>10138.750000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>3.166667</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5032.500000</td>\n",
       "      <td>20128.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7335.000000</td>\n",
       "      <td>29338.250000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9813.000000</td>\n",
       "      <td>39252.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                ID       TASK_ID      STORES1   TRANSPORT1        CITY1  \\\n",
       "count  9032.000000   9032.000000  9032.000000  9032.000000  9032.000000   \n",
       "mean   4938.589460  19752.857839     7.981842     7.978299     3.007418   \n",
       "std    2798.272394  11193.089632     4.945691     4.966099     1.581524   \n",
       "min       2.000000      5.000000     2.000000     2.000000     1.000000   \n",
       "25%    2535.000000  10138.750000     5.000000     2.000000     2.000000   \n",
       "50%    5032.500000  20128.500000     5.000000     5.000000     4.000000   \n",
       "75%    7335.000000  29338.250000    10.000000    15.000000     5.000000   \n",
       "max    9813.000000  39252.000000    15.000000    15.000000     5.000000   \n",
       "\n",
       "            NOISE1       GREEN1     FOREIGN1      STORES2   TRANSPORT2  ...  \\\n",
       "count  9032.000000  9032.000000  9032.000000  9032.000000  9032.000000  ...   \n",
       "mean      2.496678     2.503432     0.249302     8.002214     7.948406  ...   \n",
       "std       1.121651     1.112332     0.111112     4.939272     4.931868  ...   \n",
       "min       1.000000     1.000000     0.100000     2.000000     2.000000  ...   \n",
       "25%       1.000000     2.000000     0.200000     5.000000     2.000000  ...   \n",
       "50%       3.000000     3.000000     0.200000    10.000000     5.000000  ...   \n",
       "75%       4.000000     3.000000     0.300000    10.000000    10.000000  ...   \n",
       "max       4.000000     4.000000     0.400000    15.000000    15.000000  ...   \n",
       "\n",
       "          FOREIGN3          AGE        WOMAN    HOMEOWNER     CAROWNER  \\\n",
       "count  9032.000000  9032.000000  9032.000000  9032.000000  9032.000000   \n",
       "mean      0.250498    44.530115     0.532329     0.224092     0.624004   \n",
       "std       0.112500    13.463328     0.498981     0.417006     0.484406   \n",
       "min       0.100000    18.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.100000    33.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.300000    44.000000     1.000000     0.000000     1.000000   \n",
       "75%       0.400000    56.000000     1.000000     0.000000     1.000000   \n",
       "max       0.400000    70.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "          RESPCITY          JOB     EDUYEARS      ENVCONC       CHOICE  \n",
       "count  9032.000000  9032.000000  9032.000000  9032.000000  9032.000000  \n",
       "mean      2.614703     0.735607    15.254650     3.625000     1.958924  \n",
       "std       1.108207     0.441034     2.702097     0.771467     0.813718  \n",
       "min       1.000000     0.000000     8.000000     1.000000     1.000000  \n",
       "25%       2.000000     0.000000    13.000000     3.166667     1.000000  \n",
       "50%       3.000000     1.000000    16.000000     3.666667     2.000000  \n",
       "75%       4.000000     1.000000    18.000000     4.166667     3.000000  \n",
       "max       4.000000     1.000000    18.000000     5.000000     3.000000  \n",
       "\n",
       "[8 rows x 29 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data cleaning\n",
    "\n",
    "# list of relevant features\n",
    "id         = ['ID', 'TASK_ID' ]\n",
    "attributes =   ['STORES1', 'TRANSPORT1', 'CITY1', 'NOISE1', 'GREEN1', 'FOREIGN1', \n",
    "                'STORES2', 'TRANSPORT2', 'CITY2', 'NOISE2', 'GREEN2', 'FOREIGN2',\n",
    "                'STORES3', 'TRANSPORT3', 'CITY3', 'NOISE3', 'GREEN3', 'FOREIGN3']\n",
    "\n",
    "sociovars = ['AGE','WOMAN','HOMEOWNER','CAROWNER','RESPCITY', 'JOB', 'EDUYEARS', 'ENVCONC']\n",
    "\n",
    "# Create a new instance of the dataframe, with the atrtributes, socio-demographic variables and the choice\n",
    "dff = df[ id + attributes + sociovars + ['CHOICE']].copy()\n",
    "\n",
    "# Replace 9999 with NaN\n",
    "dff = dff.replace(99999, np.nan)\n",
    "\n",
    "# Remove rows with missing data in the relevant features\n",
    "dff = dff.dropna(subset=sociovars, how='any')\n",
    "\n",
    "dff.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recode categorical socio demographic variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe with the relevant socio demographic variables\n",
    "df_sociovars  = dff[sociovars].astype(int)\n",
    "\n",
    "# Recode 'AGE' in three categorical levels.\n",
    "df_sociovars.loc[(      df_sociovars['AGE'] < 25), 'AGE'] = 1\n",
    "df_sociovars.loc[(25 <= df_sociovars['AGE']     ) &\n",
    "                 (      df_sociovars['AGE'] < 60), 'AGE'] = 2\n",
    "df_sociovars.loc[(60 <= df_sociovars['AGE']     ), 'AGE'] = 3\n",
    "\n",
    "# Recode 'EDUYEARS' in three categorical levels.\n",
    "df_sociovars.loc[(      df_sociovars['EDUYEARS'] < 10), 'EDUYEARS'] = 1\n",
    "df_sociovars.loc[(10 <= df_sociovars['EDUYEARS']     ) & \n",
    "                 (      df_sociovars['EDUYEARS'] < 14), 'EDUYEARS'] = 2\n",
    "df_sociovars.loc[(14 <= df_sociovars['EDUYEARS']     ), 'EDUYEARS'] = 3\n",
    "\n",
    "# Recode 'ENVCONC' in three categorical levels.\n",
    "df_sociovars.loc[(     df_sociovars['ENVCONC'] < 3), 'ENVCONC'] = 1\n",
    "df_sociovars.loc[(3 <= df_sociovars['ENVCONC']    ) & \n",
    "                 (     df_sociovars['ENVCONC'] < 4), 'ENVCONC'] = 2\n",
    "df_sociovars.loc[(4 <= df_sociovars['ENVCONC']    ), 'ENVCONC'] = 3\n",
    "\n",
    "# Convert categorical variables to dummy variables using pd.get_dummies()\n",
    "df_sociovars = pd.get_dummies(data = df_sociovars, prefix = sociovars, prefix_sep='_', columns = sociovars, drop_first = True, dtype=int)\n",
    "\n",
    "# Create a list of the names of the socio demographic variables\n",
    "features_socio = df_sociovars.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, create the dataframe for training, containing the 'ID', 'CHOICE', attributes and dummy-coded socio-demographic variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9032, 33)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>CHOICE</th>\n",
       "      <th>STORES1</th>\n",
       "      <th>TRANSPORT1</th>\n",
       "      <th>CITY1</th>\n",
       "      <th>NOISE1</th>\n",
       "      <th>GREEN1</th>\n",
       "      <th>FOREIGN1</th>\n",
       "      <th>STORES2</th>\n",
       "      <th>TRANSPORT2</th>\n",
       "      <th>...</th>\n",
       "      <th>HOMEOWNER_1</th>\n",
       "      <th>CAROWNER_1</th>\n",
       "      <th>RESPCITY_2</th>\n",
       "      <th>RESPCITY_3</th>\n",
       "      <th>RESPCITY_4</th>\n",
       "      <th>JOB_1</th>\n",
       "      <th>EDUYEARS_2</th>\n",
       "      <th>EDUYEARS_3</th>\n",
       "      <th>ENVCONC_2</th>\n",
       "      <th>ENVCONC_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9032.000000</td>\n",
       "      <td>9032.000000</td>\n",
       "      <td>9032.000000</td>\n",
       "      <td>9032.000000</td>\n",
       "      <td>9032.000000</td>\n",
       "      <td>9032.000000</td>\n",
       "      <td>9032.000000</td>\n",
       "      <td>9032.000000</td>\n",
       "      <td>9032.000000</td>\n",
       "      <td>9032.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>9032.000000</td>\n",
       "      <td>9032.000000</td>\n",
       "      <td>9032.000000</td>\n",
       "      <td>9032.000000</td>\n",
       "      <td>9032.000000</td>\n",
       "      <td>9032.000000</td>\n",
       "      <td>9032.000000</td>\n",
       "      <td>9032.000000</td>\n",
       "      <td>9032.00000</td>\n",
       "      <td>9032.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4938.589460</td>\n",
       "      <td>1.958924</td>\n",
       "      <td>7.981842</td>\n",
       "      <td>7.978299</td>\n",
       "      <td>3.007418</td>\n",
       "      <td>2.496678</td>\n",
       "      <td>2.503432</td>\n",
       "      <td>0.249302</td>\n",
       "      <td>8.002214</td>\n",
       "      <td>7.948406</td>\n",
       "      <td>...</td>\n",
       "      <td>0.224092</td>\n",
       "      <td>0.624004</td>\n",
       "      <td>0.176705</td>\n",
       "      <td>0.327724</td>\n",
       "      <td>0.260850</td>\n",
       "      <td>0.735607</td>\n",
       "      <td>0.323295</td>\n",
       "      <td>0.643047</td>\n",
       "      <td>0.44597</td>\n",
       "      <td>0.370682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2798.272394</td>\n",
       "      <td>0.813718</td>\n",
       "      <td>4.945691</td>\n",
       "      <td>4.966099</td>\n",
       "      <td>1.581524</td>\n",
       "      <td>1.121651</td>\n",
       "      <td>1.112332</td>\n",
       "      <td>0.111112</td>\n",
       "      <td>4.939272</td>\n",
       "      <td>4.931868</td>\n",
       "      <td>...</td>\n",
       "      <td>0.417006</td>\n",
       "      <td>0.484406</td>\n",
       "      <td>0.381440</td>\n",
       "      <td>0.469409</td>\n",
       "      <td>0.439123</td>\n",
       "      <td>0.441034</td>\n",
       "      <td>0.467760</td>\n",
       "      <td>0.479127</td>\n",
       "      <td>0.49710</td>\n",
       "      <td>0.483014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2535.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5032.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7335.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9813.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                ID       CHOICE      STORES1   TRANSPORT1        CITY1  \\\n",
       "count  9032.000000  9032.000000  9032.000000  9032.000000  9032.000000   \n",
       "mean   4938.589460     1.958924     7.981842     7.978299     3.007418   \n",
       "std    2798.272394     0.813718     4.945691     4.966099     1.581524   \n",
       "min       2.000000     1.000000     2.000000     2.000000     1.000000   \n",
       "25%    2535.000000     1.000000     5.000000     2.000000     2.000000   \n",
       "50%    5032.500000     2.000000     5.000000     5.000000     4.000000   \n",
       "75%    7335.000000     3.000000    10.000000    15.000000     5.000000   \n",
       "max    9813.000000     3.000000    15.000000    15.000000     5.000000   \n",
       "\n",
       "            NOISE1       GREEN1     FOREIGN1      STORES2   TRANSPORT2  ...  \\\n",
       "count  9032.000000  9032.000000  9032.000000  9032.000000  9032.000000  ...   \n",
       "mean      2.496678     2.503432     0.249302     8.002214     7.948406  ...   \n",
       "std       1.121651     1.112332     0.111112     4.939272     4.931868  ...   \n",
       "min       1.000000     1.000000     0.100000     2.000000     2.000000  ...   \n",
       "25%       1.000000     2.000000     0.200000     5.000000     2.000000  ...   \n",
       "50%       3.000000     3.000000     0.200000    10.000000     5.000000  ...   \n",
       "75%       4.000000     3.000000     0.300000    10.000000    10.000000  ...   \n",
       "max       4.000000     4.000000     0.400000    15.000000    15.000000  ...   \n",
       "\n",
       "       HOMEOWNER_1   CAROWNER_1   RESPCITY_2   RESPCITY_3   RESPCITY_4  \\\n",
       "count  9032.000000  9032.000000  9032.000000  9032.000000  9032.000000   \n",
       "mean      0.224092     0.624004     0.176705     0.327724     0.260850   \n",
       "std       0.417006     0.484406     0.381440     0.469409     0.439123   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     1.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     1.000000     0.000000     1.000000     1.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "             JOB_1   EDUYEARS_2   EDUYEARS_3   ENVCONC_2    ENVCONC_3  \n",
       "count  9032.000000  9032.000000  9032.000000  9032.00000  9032.000000  \n",
       "mean      0.735607     0.323295     0.643047     0.44597     0.370682  \n",
       "std       0.441034     0.467760     0.479127     0.49710     0.483014  \n",
       "min       0.000000     0.000000     0.000000     0.00000     0.000000  \n",
       "25%       0.000000     0.000000     0.000000     0.00000     0.000000  \n",
       "50%       1.000000     0.000000     1.000000     0.00000     0.000000  \n",
       "75%       1.000000     1.000000     1.000000     1.00000     1.000000  \n",
       "max       1.000000     1.000000     1.000000     1.00000     1.000000  \n",
       "\n",
       "[8 rows x 33 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate the socio demographic variables with the relevant features of the alternatives\n",
    "dff = pd.concat([dff[['ID', 'CHOICE'] + attributes], df_sociovars], axis=1)\n",
    "\n",
    "print(dff.shape)\n",
    "dff.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ii. Split the data in a test and train set`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of individuals in the df_train and df_test: \t1832  426 \n",
      "Number of observations in the df_train and df_test: \t7328 1704 \n"
     ]
    }
   ],
   "source": [
    "# Set a seed for reproducibilty\n",
    "np.random.seed(100)\n",
    "dff['draw']=float('nan')\n",
    "for i in dff['ID'].unique():\n",
    "    num_obs = len(dff.loc[dff['ID']==i,'draw'])\n",
    "    dff.loc[dff['ID']==i,'draw']= np.repeat(np.random.uniform(0,1,1),num_obs)\n",
    "\n",
    "# Put 80% of the data in the training set and 20% in the test set\n",
    "df_train = dff.loc[dff['draw']< 0.8,:].copy()\n",
    "df_test  = dff.loc[dff['draw']>=0.8,:].copy()\n",
    "\n",
    "# Number of observations in the training and test sets\n",
    "num_obs_train = len(df_train)\n",
    "num_obs_test  = len(df_test)\n",
    "\n",
    "print(f'Number of individuals in the df_train and df_test: \\t{df_train.ID.nunique()}  {df_test.ID.nunique()} ')\n",
    "print(f'Number of observations in the df_train and df_test: \\t{len(df_train)} {len(df_test)} ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`iii. Scaling the features`<br>\n",
    "To efficiently train ANNs it strongly recommended to scale (a.k.a. normalise) the features. There are several ways to scale your data. A commonly used scaler of sk-learn is called 'StandardScaler'. This scaler normalises the variance and shift the location of the distribution to zero, see https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train (7328, 31)\n",
      "Shape of x_test (1704, 31)\n"
     ]
    }
   ],
   "source": [
    "# Create X_train and X_test\n",
    "x_train = df_train[attributes + features_socio]\n",
    "x_test  = df_test [attributes + features_socio]\n",
    "\n",
    "# Initialize the scaler object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the training data\n",
    "scaler = scaler.fit(dff[attributes + features_socio])\n",
    "\n",
    "# Apply the fitted scaler to the  data sets\n",
    "x_train_scaled = pd.DataFrame(scaler.transform(df_train[attributes + features_socio]), columns=[attributes + features_socio])\n",
    "x_test_scaled =  pd.DataFrame(scaler.transform(df_test [attributes + features_socio]), columns=[attributes + features_socio]) \n",
    "\n",
    "print('Shape of x_train', x_train_scaled.shape)\n",
    "print('Shape of x_test', x_test_scaled.shape)\n",
    "\n",
    "# Create the target values\n",
    "# Y must be a dummy coded array\n",
    "y_train_dummy = pd.get_dummies(df_train['CHOICE']).values.astype(int)\n",
    "y_test_dummy = pd.get_dummies(df_test['CHOICE']).values.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`iv. Conversion to tensors`<br>\n",
    "Many machine learning packages work with so-called tensors. Tensors are dedicated data structures to effciently train neural networks. Therefore, we need to convert the features and the target into a tensors datatype. In PyTorch, this is done with `torch.tensor()`.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train_tensor\t torch.Size([7328, 18])\n",
      "Shape of x_test_tensor\t torch.Size([1704, 18])\n"
     ]
    }
   ],
   "source": [
    "# Create tensors for the train set\n",
    "# In this case, we use only the features of the alternatives 'features_alt'\n",
    "x_train_tensor = torch.tensor(x_train_scaled[attributes].values, dtype=torch.float)\n",
    "y_train_dummy_tensor = torch.tensor(y_train_dummy, dtype=torch.float)\n",
    "\n",
    "# Create tensors for the test set\n",
    "x_test_tensor = torch.tensor(x_test_scaled[attributes].values, dtype=torch.float)\n",
    "y_test_dummy_tensor = torch.tensor(y_test_dummy, dtype=torch.float)\n",
    "\n",
    "# Print the shapes of the tensors   \n",
    "print('Shape of x_train_tensor\\t', x_train_tensor.shape)\n",
    "print('Shape of x_test_tensor\\t', x_test_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `2. Estimating a Linear-additive RUM-MNL benchmark model`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`i. Model estimation`<br>\n",
    "We first estimate our a linear-addtive RUM-MNL benchmark model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert pandas df into biogeme database\n",
    "biodata_train = db.Database('neighbourhood_data_train', df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Biogeme variables\n",
    "\n",
    "# Attributes of alternative 1\n",
    "STORES1     = Variable('STORES1')\n",
    "TRANSPORT1  = Variable('TRANSPORT1')\n",
    "CITY1       = Variable('CITY1')\n",
    "NOISE1      = Variable('NOISE1')\n",
    "GREEN1      = Variable('GREEN1')\n",
    "FOREIGN1    = Variable('FOREIGN1')\n",
    "\n",
    "# Attributes of alternative 2    \n",
    "STORES2     = Variable('STORES2')\n",
    "TRANSPORT2  = Variable('TRANSPORT2')\n",
    "CITY2       = Variable('CITY2')\n",
    "NOISE2      = Variable('NOISE2')\n",
    "GREEN2      = Variable('GREEN2')\n",
    "FOREIGN2    = Variable('FOREIGN2')\n",
    "    \n",
    "# Attributes of alternative 3\n",
    "STORES3     = Variable('STORES3')\n",
    "TRANSPORT3  = Variable('TRANSPORT3')\n",
    "CITY3       = Variable('CITY3')\n",
    "NOISE3      = Variable('NOISE3')\n",
    "GREEN3      = Variable('GREEN3')\n",
    "FOREIGN3    = Variable('FOREIGN3')\n",
    "\n",
    "# choice\n",
    "CHOICE      = Variable('CHOICE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The syntax \"shortSummary\" is deprecated and is replaced by the syntax \"short_summary\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model Linear-additive RUM-MNL\n",
      "Nbr of parameters:\t\t6\n",
      "Sample size:\t\t\t7328\n",
      "Excluded data:\t\t\t0\n",
      "Null log likelihood:\t\t-8050.631\n",
      "Final log likelihood:\t\t-6471.391\n",
      "Likelihood ratio test (null):\t\t3158.48\n",
      "Rho square (null):\t\t\t0.196\n",
      "Rho bar square (null):\t\t\t0.195\n",
      "Akaike Information Criterion:\t12954.78\n",
      "Bayesian Information Criterion:\t12996.18\n",
      "\n",
      "                Value  Rob. Std err  Rob. t-test  Rob. p-value\n",
      "B_city      -0.170377      0.009225   -18.468215           0.0\n",
      "B_foreign   -1.193204      0.125067    -9.540546           0.0\n",
      "B_green      0.416362      0.013073    31.849350           0.0\n",
      "B_noise     -0.448441      0.012045   -37.230843           0.0\n",
      "B_stores    -0.036265      0.002974   -12.193653           0.0\n",
      "B_transport -0.076922      0.002839   -27.095476           0.0\n"
     ]
    }
   ],
   "source": [
    "# Give a name to the model    \n",
    "model_name = 'Linear-additive RUM-MNL'\n",
    "\n",
    "# Define the model parameters, using the function \"Beta()\", in which you must define:\n",
    "B_stores    = Beta('B_stores'   , 0, None, None, 0)\n",
    "B_transport = Beta('B_transport', 0, None, None, 0)\n",
    "B_city      = Beta('B_city'     , 0, None, None, 0)\n",
    "B_noise     = Beta('B_noise'    , 0, None, None, 0)\n",
    "B_green     = Beta('B_green'    , 0, None, None, 0)\n",
    "B_foreign   = Beta('B_foreign'  , 0, None, None, 0)\n",
    "\n",
    "# Define the utility functions\n",
    "V1 = B_stores * STORES1 + B_transport * TRANSPORT1 + B_city * CITY1 + B_noise * NOISE1 + B_green * GREEN1 + B_foreign * FOREIGN1\n",
    "V2 = B_stores * STORES2 + B_transport * TRANSPORT2 + B_city * CITY2 + B_noise * NOISE2 + B_green * GREEN2 + B_foreign * FOREIGN2\n",
    "V3 = B_stores * STORES3 + B_transport * TRANSPORT3 + B_city * CITY3 + B_noise * NOISE3 + B_green * GREEN3 + B_foreign * FOREIGN3\n",
    "\n",
    "# Associate utility functions with alternatives\n",
    "V = {1: V1, 2: V2, 3: V3}    \n",
    "\n",
    "# Associate the availability conditions with the alternatives\n",
    "AV = {1: 1, 2: 1, 3: 1} \n",
    "\n",
    "# Definition of the model. This is the contribution of each observation to the log likelihood function.\n",
    "prob = models.logit(V, AV, CHOICE)\n",
    "\n",
    "# Create the Biogeme object\n",
    "biogeme = bio.BIOGEME(biodata_train, log(prob))\n",
    "\n",
    "# Set reporting levels\n",
    "biogeme.generate_pickle = False\n",
    "biogeme.generate_html = False\n",
    "biogeme.saveIterations = False\n",
    "biogeme.modelName = model_name\n",
    "\n",
    "# Compute the null loglikelihood for reporting\n",
    "biogeme.calculateNullLoglikelihood(AV)\n",
    "\n",
    "# Estimate the parameters\n",
    "results = biogeme.estimate()\n",
    "print(results.shortSummary())\n",
    "\n",
    "# Get the results in a pandas table\n",
    "beta_hat = results.getEstimatedParameters()\n",
    "print(beta_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ii. Compute the LL of the estimated model on the test set`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LL MNL test: -1543.88\n"
     ]
    }
   ],
   "source": [
    "# Create the biogeme simulation object\n",
    "biodate_test = db.Database('Neighbourhood_data_test', df_test)\n",
    "\n",
    "# Simulate th choice probability for the MNL model on the test set\n",
    "dict2simulate = {'prob_chosen':prob}\n",
    "\n",
    "# Create the Biogeme simulation object\n",
    "biosim = bio.BIOGEME(biodate_test,dict2simulate)\n",
    "simulated_probs = biosim.simulate(theBetaValues=results.getBetaValues())\n",
    "\n",
    "# Calculate the log-likelihood of the MNL model on the test set and print it\n",
    "LL_MNL_test = np.log(simulated_probs['prob_chosen']).sum()\n",
    "print(f'LL MNL test: {LL_MNL_test:0.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ``Exercise 1: Willingness to pay for grocery stores``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`A` Calculate the willingness to pay reduce the number of walking minutes to the grocery stores by one minute, expressed in terms of walking minutes to the public transport. Use formula:<br><br>\n",
    "$WTP = \\frac{\\beta_{stores}}{\\beta_{transport}}$<br><br>\n",
    "`B` Interpret this result. What do people find more important; walking minutes to grocery stores or walking minutes to public transport?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{green}{\\text{Add your answers here}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Willigness to pay to reduce one minute of walking time to the grocery store is: 0.47 walking minutes to the public transport\n",
      "\n",
      "Distance to the public transport almost twice as important than distance to the grocery store because the WTP is < 1\n"
     ]
    }
   ],
   "source": [
    "# ANSWERS\n",
    "# A\n",
    "WTP_MNL = beta_hat.loc['B_stores']['Value']/beta_hat.loc['B_transport']['Value']\n",
    "print(f'\\nWilligness to pay to reduce one minute of walking time to the grocery store is: {WTP_MNL:.2f} walking minutes to the public transport')\n",
    "\n",
    "# B\n",
    "print('\\nDistance to the public transport almost twice as important than distance to the grocery store because the WTP is < 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `3. The MLP model`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A MultiLayer Perceptron (MLP) is a neural network widely used in machine learning because of its ability to learn complex patterns. It is composed of hidden layers with neurons and activation functions. <br>\n",
    "\n",
    "For example, in the following image, we can see an input layer with 8 features, two hidden layers with each 10 hidden nodes, and the output layer with 3 output classes:<br>\n",
    "\n",
    "<p align=\"center\\\">\n",
    "<img width=\"800\" src=\"Assets/MLP.png\">\n",
    "</p> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`i. Define MLP model`<br>\n",
    "We will create a fully connected neural network with two hidden layers. To do so, we create a new class using PyTorch's nn.Module. We define how the object is initialised.In this case, we will have an input layer of size `input_size`, two hidden layers with sizes `hidden_size1` and `hidden_size2` respectively, and an output layer of size `output_size`. Additionally, we define the forward function. The forward function takes an input value `x`, passes it through the network layers, while applying activation functions. It outputs the utilities of each alternative `V`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fully connected neural network with two hidden layer\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, output_size):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.fc3 = nn.Linear(hidden_size2, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.tanh(self.fc1(x)) # tanh activation function for the 1st layer\n",
    "        x = torch.tanh(self.fc2(x)) # tanh activation function for the 2nd layer\n",
    "        V = self.fc3(x)             # linear activation function for the output layer\n",
    "\n",
    "        return V                    # return the \"Utility\" of each alternative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ii. Create DataLoaders`<br>\n",
    "A PyTorch Dataloader object effciently handles the data flow during training and testing. It creates the minibatches, and ensures that are instances of the data are depleted each epoch. <br>We create a DataLoader for both the train and test data sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataLoader for the train set\n",
    "dataset_train = TensorDataset(x_train_tensor, y_train_dummy_tensor)\n",
    "train_loader = DataLoader(dataset_train, batch_size=250, shuffle=True)\n",
    "\n",
    "# Create a DataLoader for the test set\n",
    "dataset_test = TensorDataset(x_test_tensor, y_test_dummy_tensor)\n",
    "test_loader = DataLoader(dataset_test, batch_size=len(x_test_tensor), shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`iii. Define functions`<br>\n",
    "We define the the following functions:\n",
    "1. a function to evaluate the model performance during training\n",
    "2. a function to visualise the training progress\n",
    "3. a function to inspect the model object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, criterion, data_loader):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    total_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in data_loader:\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function visualises the training progress. We call this function after the training is finished."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_loss_plot(train_losses, test_losses, num_obs_train, num_obs_test):\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    ax.plot(np.array(train_losses)/num_obs_train, label='Training Loss')\n",
    "    ax.plot(np.array(test_losses)/num_obs_test,   label='Test Loss')\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Loss')\n",
    "    ax.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function allows us to inspect the created model architecture. It lists the number of weights per layer, and their input and output sizes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_model_summary(model):\n",
    "    total_params = 0\n",
    "    print(f\"=== Model Summary ===\")\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            num_params = param.numel()\n",
    "            total_params += num_params\n",
    "            print(f\"Layer: {name:20}|\\t Weights: {num_params}\")\n",
    "\n",
    "    print(f\"\\nTotal trainable Weights: {total_params}\")\n",
    "\n",
    "    print(\"\\n=== Layers ===\")\n",
    "    for layer in model.children():\n",
    "        print(layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`iv. Create the MLP object`<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " input_size = 18, hidden_size1 = 10, hidden_size2 = 10, output_size = 3\n"
     ]
    }
   ],
   "source": [
    "# Define the dimensions of the MLP\n",
    "input_size   = x_train_tensor.size()[1]  # Number of input features\n",
    "hidden_size1 = 10                        # Number of units in first hidden layer\n",
    "hidden_size2 = 10                        # Number of units in second hidden layer\n",
    "output_size  = 3                         # Number of output classes (determined by the number of alternatives)\n",
    "print(f' input_size = {input_size}, hidden_size1 = {hidden_size1}, hidden_size2 = {hidden_size2}, output_size = {output_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Model Summary ===\n",
      "Layer: fc1.weight          |\t Weights: 180\n",
      "Layer: fc1.bias            |\t Weights: 10\n",
      "Layer: fc2.weight          |\t Weights: 100\n",
      "Layer: fc2.bias            |\t Weights: 10\n",
      "Layer: fc3.weight          |\t Weights: 30\n",
      "Layer: fc3.bias            |\t Weights: 3\n",
      "\n",
      "Total trainable Weights: 333\n",
      "\n",
      "=== Layers ===\n",
      "Linear(in_features=18, out_features=10, bias=True)\n",
      "Linear(in_features=10, out_features=10, bias=True)\n",
      "Linear(in_features=10, out_features=3, bias=True)\n"
     ]
    }
   ],
   "source": [
    "# Invoke the MLP model\n",
    "model = MLP(input_size, hidden_size1, hidden_size2, output_size)\n",
    "\n",
    "# Print the model architecture\n",
    "print_model_summary(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define settings for the training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`v. Train the MLP model`<br>\n",
    "Finally, we are ready to train the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "nEpoch = 500  # Set the number of epochs\n",
    "lr = 0.0001  # Set the learning rate\n",
    "status = 10  # Print status every 'status' epochs\n",
    "patience = 5  # Number of epochs to wait before early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [    1/500], Train Loss: 8010.471, Test Loss: 1869.494\n",
      "Epoch [   10/500], Train Loss: 7642.229, Test Loss: 1785.061\n",
      "Epoch [   20/500], Train Loss: 7186.391, Test Loss: 1683.929\n",
      "Epoch [   30/500], Train Loss: 6773.080, Test Loss: 1595.190\n",
      "Epoch [   40/500], Train Loss: 6487.396, Test Loss: 1535.113\n",
      "Epoch [   50/500], Train Loss: 6308.095, Test Loss: 1498.632\n",
      "Epoch [   60/500], Train Loss: 6200.033, Test Loss: 1477.788\n",
      "Epoch [   70/500], Train Loss: 6137.681, Test Loss: 1466.320\n",
      "Epoch [   80/500], Train Loss: 6103.129, Test Loss: 1460.115\n",
      "Epoch [   90/500], Train Loss: 6083.136, Test Loss: 1456.863\n",
      "Epoch [  100/500], Train Loss: 6071.249, Test Loss: 1454.810\n",
      "Epoch [  110/500], Train Loss: 6063.626, Test Loss: 1453.696\n",
      "Epoch [  120/500], Train Loss: 6058.223, Test Loss: 1452.959\n",
      "Epoch [  130/500], Train Loss: 6054.099, Test Loss: 1452.573\n",
      "Epoch [  140/500], Train Loss: 6050.689, Test Loss: 1452.268\n",
      "Epoch [  150/500], Train Loss: 6048.014, Test Loss: 1451.679\n",
      "Epoch [  160/500], Train Loss: 6045.669, Test Loss: 1451.396\n",
      "Early stopping at epoch 165\n",
      "\n",
      "Training finished.\tTrain Loss: 6044.436, Test Loss: 1451.435\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "do_training = True\n",
    "if do_training == True:\n",
    "\n",
    "    # Define the model, loss function and optimizer\n",
    "    \n",
    "    optimizer = optim.Adam(params=model.parameters(), lr=lr,  betas=(0.9, 0.999), eps=1e-07, weight_decay=0)\n",
    "    loss_fn = nn.CrossEntropyLoss(reduction='sum')\n",
    "\n",
    "    # Define lists to store losses\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "\n",
    "    # Initialize early stopping counter \n",
    "    counter = 0\n",
    "    best_loss = np.inf  # Set initial loss to infinity\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(nEpoch):\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)   \n",
    "\n",
    "            # Compute the loss\n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Update running loss\n",
    "            running_loss += loss.item() # Log-likelihood on the training set\n",
    "\n",
    "        # Evaluate on the test set\n",
    "        test_loss = evaluate(model, loss_fn, test_loader) # Log-likelihood on the test set\n",
    "\n",
    "        # Print status every 'status' epochs or epoch 0\n",
    "        if epoch == 0 or (epoch + 1) % status == 0:\n",
    "            print(f'Epoch [{epoch+1:5.0f}/{nEpoch}], Train Loss: {running_loss:0.3f}, Test Loss: {test_loss:0.3f}')\n",
    "\n",
    "        # Store losses\n",
    "        train_losses.append(running_loss)\n",
    "        test_losses.append(test_loss)\n",
    "\n",
    "        # Implement early stopping\n",
    "        if test_loss < best_loss:\n",
    "            best_loss = test_loss\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter += 1\n",
    "            if counter >= patience:\n",
    "                print(f'Early stopping at epoch {epoch+1}')\n",
    "                break\n",
    "            \n",
    "    print(f'\\nTraining finished.\\tTrain Loss: {running_loss:0.3f}, Test Loss: {test_loss:0.3f}')\n",
    "    show_loss_plot(train_losses, test_losses,num_obs_train, num_obs_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Exercise 2: Training the MLP model`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`A` Compare the performance on the test set of the MLP with the benchmark MNL. Has it (much) improved? What does this tell us? <br>\n",
    "`B` Retrain the MLP using the following architectures: {hidden_size1,hidden_size2} = {1,1}, {3,3}, {1,20}, {20,1}, {20,3}, {20,20}<br>\n",
    "`C` Does increasing the number of nodes lead to better generalisation performance (i.e. higher LL_test)? What is happening?<br>\n",
    "`D` Explain why {1,1} and either {20,1} and {1,20} lead to a poor performance. <br>\n",
    "`E` Retrain your model with a smaller and larger learning rate: lr = 0.01 and lr = 0.00001. Use {hidden_size1,hidden_size2} = {5,5}. Explain what is happening."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{green}{\\text{Add your answers here}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWERS\n",
    "#`A` The MLP improves the model fit by  almost 100 LL points. This is a lot. It tells the linear-additive utility assumption is too restrictive.\n",
    "\n",
    "#`B`\n",
    "#{1,1} gives a poor generalisation performance: LL = ~-1590\n",
    "#{3,3} gives an okay generalisation performance: LL = ~-1400\n",
    "#{1,20} gives a poor generalisation performance: LL = ~-1500\n",
    "#{20,1} gives an poor generalisation performance: LL = ~-1500\n",
    "#{20,3} gives an okay generalisation performance: LL = ~-1400 \n",
    "\n",
    "#`C` Increasing it from {1,1} to {3,3} increase the perf on LL_test. But {20,20} does not help it to further increase. \n",
    "\n",
    "#`D` All information is squashed to one node. Therefore, the models is not able to associate features to alternatives, leading to a poor performance.\n",
    "\n",
    "#`E` A large lr leads to quick training. But instability near the convergence. A small lr leads to slow training. The model was not nearly converged when the maximum number of training epochs was reached. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Exercise 3: Adding the socio-demographic features`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Section 1 under `iv. Conversion to tensors` we choose to use only the features of the alternatives as inputs (i.e. `features_alt`), while in lab session 1 we saw that at least gender (`WOMAN`) and the residential city (`RESPCITY`) have some eplanatory power.<br>\n",
    "\n",
    "`A` Modify the code in this cell so that also these socio demographic features are used. Then, retrain the MLP.<br>\n",
    "`B` Perhaps counter to your expectations, the model performance does not increase much. \n",
    "What does this tell us about: \n",
    "1. the explanatory power of socio-demographics to the residential location choice, and \n",
    "2. the ability of MLP models to learn subtle interaction effects? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{green}{\\text{Add your answers here}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWERS\n",
    "do_exercise3 = False\n",
    "if do_exercise3 == True:\n",
    "    #### Recreate tensors for the train set ####\n",
    "    features_alt = attributes\n",
    "    #In this case, we use the characteristics of the alternatives 'features_alt', WOMAN and RESPCITY.\n",
    "    selected_features = features_alt + ['WOMAN_1', 'RESPCITY_2', 'RESPCITY_3', 'RESPCITY_4']\n",
    "\n",
    "    x_train_tensor = torch.tensor(x_train_scaled[selected_features].values, dtype=torch.float)\n",
    "    y_train_dummy_tensor = torch.tensor(y_train_dummy, dtype=torch.float)\n",
    "\n",
    "    x_test_tensor = torch.tensor(x_test_scaled[selected_features].values, dtype=torch.float)\n",
    "    y_test_dummy_tensor = torch.tensor(y_test_dummy, dtype=torch.float)\n",
    "\n",
    "\n",
    "\n",
    "    #### Recreate DataLoader ####\n",
    "    dataset_train = TensorDataset(x_train_tensor, y_train_dummy_tensor)\n",
    "    train_loader = DataLoader(dataset_train, batch_size=250, shuffle=True)\n",
    "\n",
    "    dataset_test = TensorDataset(x_test_tensor, y_test_dummy_tensor)\n",
    "    test_loader = DataLoader(dataset_test, batch_size=len(x_test_tensor), shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "    #### Redefine the dimension of the MLP  ####\n",
    "    input_size   = x_train_tensor.size()[1]  # Number of input features\n",
    "    hidden_size1 = 20                        # Number of units in first hidden layer\n",
    "    hidden_size2 = 20                        # Number of units in second hidden layer\n",
    "    output_size  = 3                         # Number of output classes (determined by the number of alternatives)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `4. The L-MNL model `"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will build and train a hybrid model, namely the L-MNL model. This model combines an interpretable part following the assumptions of the MNL model and a neural network that processes the rest of the variables that we do not want to interpret. More specifically, we want the **flexibility** of the MLP but still want to get out an **estimate of the willingness to pay to reduce the walking distance to the grocery stores, expressed in terms of distance to the public transport**.\n",
    "\n",
    "The figure below conceptually shows this model:<br>\n",
    "\n",
    "<p align=\"center\">\n",
    "<img width=\"600\" src=\"assets/hybrid_model.png\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`i. Define the L-MNL model`<br>\n",
    "To create the L-MNL model,we create a new class using PyTorch's nn.Module. <br>\n",
    "* The MNL part is implemented with separate linear layers for features (transport and foreign), allowing the utility to be calculated for each alternative. <br>\n",
    "* The MLP part consists of two hidden layers (linear1 and linear2) with a given number of neurons.<br>\n",
    "* The forward function takes `x_mnl` and `x_mlp` as inputs. x_mlp is passed through the network layers, while applying activation functions. It outputs the utilities of each alternative `V_MLP`. x_mnl is used to compute utilities in a linear-additive fashion. \n",
    "* Finally, the utilities of boths parts are summed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LMNL(nn.Module):\n",
    "    def __init__(self, input_size_mlp, hidden_size1, hidden_size2,output_size):\n",
    "        super(LMNL,self).__init__()\n",
    "\n",
    "        # Create betas for the MNL part\n",
    "        self.B_transport = nn.Linear(1, 1, bias=False )\n",
    "        self.B_stores   = nn.Linear(1, 1, bias=False )\n",
    "                                 \n",
    "        # Create the hidden layers for the MLP part\n",
    "        self.linear1 = nn.Linear(input_size_mlp, hidden_size1, bias=False)\n",
    "        self.linear2 = nn.Linear(hidden_size1,   hidden_size2, bias=False) \n",
    "        self.linear3 = nn.Linear(hidden_size2,   output_size,  bias=False) \n",
    "\n",
    "    def forward(self, X_MNL, X_MLP):\n",
    "        \n",
    "        # Utility functions for the MNL part \n",
    "        V_A = self.B_transport(X_MNL[:,0].unsqueeze(1))  + self.B_stores(X_MNL[:,1].unsqueeze(1))\n",
    "        V_B = self.B_transport(X_MNL[:,2].unsqueeze(1))  + self.B_stores(X_MNL[:,3].unsqueeze(1))\n",
    "        V_C = self.B_transport(X_MNL[:,4].unsqueeze(1))  + self.B_stores(X_MNL[:,5].unsqueeze(1))\n",
    "                     \n",
    "        # Concatenating tensors to maintain the output dimension\n",
    "        V_MNL = torch.cat((V_A, V_B, V_C), dim=1)\n",
    "\n",
    "        # The MLP part\n",
    "        X_MLP = torch.tanh(self.linear1(X_MLP)) # tanh activation function for the 1st layer\n",
    "        X_MLP = torch.tanh(self.linear2(X_MLP)) # tanh activation function for the 2nd layer\n",
    "        V_MLP = self.linear3(X_MLP)             # linear activation function for the output layer\n",
    "\n",
    "        # Sum the utilities from the MNL and MLP parts\n",
    "        V = V_MNL + V_MLP\n",
    "        return V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ii. Prepare the data for training the L-MNL model`<br>\n",
    "We need to split the features going into the MLP and MNL parts. Because we want to compute the WTP of stores over transport. Therefore, the features related to transport and stores go into the MNL part, while the other features, including socio-demographics, go into the MLP part. **Importantly**, the MNL features must NOT be scaled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_mnl_train\t (7328, 6)\n",
      "Shape of x_mnl_test\t (1704, 6)\n",
      "\n",
      "Shape of x_mlp_train\t (7328, 15)\n",
      "Shape of x_mlp_test\t (1704, 15)\n"
     ]
    }
   ],
   "source": [
    "# Create dataframe with features for MNL part\n",
    "features_mnl = ['TRANSPORT1', 'STORES1','TRANSPORT2', 'STORES2','TRANSPORT3', 'STORES3']\n",
    "x_mnl_train = x_train[features_mnl]\n",
    "x_mnl_test  = x_test[features_mnl]\n",
    "\n",
    "print('Shape of x_mnl_train\\t', x_mnl_train.shape)\n",
    "print('Shape of x_mnl_test\\t', x_mnl_test.shape)\n",
    "\n",
    "# Create dataframe with features for MLP part\n",
    "features_mlp_alt = ['FOREIGN1', 'CITY1', 'NOISE1', 'GREEN1', \n",
    "                    'FOREIGN2', 'CITY2', 'NOISE2', 'GREEN2', \n",
    "                    'FOREIGN3', 'CITY3', 'NOISE3', 'GREEN3']\n",
    "\n",
    "\n",
    "features_socio = ['RESPCITY_2','RESPCITY_3','RESPCITY_4']\n",
    "x_mlp_train = x_train_scaled[features_mlp_alt + features_socio]\n",
    "x_mlp_test  = x_test_scaled[features_mlp_alt + features_socio]\n",
    "\n",
    "print('\\nShape of x_mlp_train\\t', x_mlp_train.shape)\n",
    "print('Shape of x_mlp_test\\t', x_mlp_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert data to PyTorch tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the X_mnl_train tensor =  torch.Size([7328, 6])\n",
      "Size of the X_mlp_train tensor =  torch.Size([7328, 15])\n",
      "\n",
      "Size of the X_mnl_test tensor  =  torch.Size([1704, 6])\n",
      "Size of the X_mlp_test tensor  =  torch.Size([1704, 15])\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "x_mnl_train_tensor = torch.tensor(x_mnl_train.values, dtype=torch.float)\n",
    "x_mlp_train_tensor = torch.tensor(x_mlp_train.values, dtype=torch.float)\n",
    "y_train_dummy_tensor = torch.tensor(y_train_dummy,    dtype=torch.float)\n",
    "\n",
    "# test\n",
    "x_mnl_test_tensor = torch.tensor(x_mnl_test.values, dtype=torch.float)\n",
    "x_mlp_test_tensor = torch.tensor(x_mlp_test.values, dtype=torch.float)\n",
    "y_test_dummy_tensor = torch.tensor(y_test_dummy,    dtype=torch.float)\n",
    "\n",
    "print('Size of the X_mnl_train tensor = ', x_mnl_train_tensor.size())\n",
    "print('Size of the X_mlp_train tensor = ', x_mlp_train_tensor.size())\n",
    "print('\\nSize of the X_mnl_test tensor  = ', x_mnl_test_tensor.size())\n",
    "print('Size of the X_mlp_test tensor  = ', x_mlp_test_tensor.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create PyTorch DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataLoader for the train set\n",
    "dataset_train_lmnl = TensorDataset(x_mnl_train_tensor, x_mlp_train_tensor, y_train_dummy_tensor)\n",
    "train_loader_lmnl = DataLoader(dataset_train_lmnl, batch_size=250, shuffle=True)\n",
    "\n",
    "# Create a DataLoader for the test set\n",
    "dataset_test_lmnl = TensorDataset(x_mnl_test_tensor, x_mlp_test_tensor, y_test_dummy_tensor)\n",
    "test_loader_lmnl = DataLoader(dataset_test_lmnl, batch_size=len(x_test_tensor), shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`iii. Define functions`<br>\n",
    "We cannot re-use the evaluation function we created before, because this model takes two inputs (x_mnl, x_mlp), instead of one. Therefore, we create a new one for the L-MNL model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_lmnl(model, criterion, data_loader):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    total_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x_mnl, x_mlp, labels in data_loader:\n",
    "            outputs = model(x_mnl,x_mlp)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`iv. Create the L-MNL model object`<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " input_size_mnl = 6, input_size_mlp = 15, hidden_size1 = 10, hidden_size2 = 10, output_size = 3\n"
     ]
    }
   ],
   "source": [
    "# Define the dimensions\n",
    "input_size_mnl = x_mnl_train_tensor.size()[1]  # Number of input features\n",
    "input_size_mlp = x_mlp_train_tensor.size()[1]  # Number of input features\n",
    "hidden_size1 = 10  # Number of units in first hidden layer\n",
    "hidden_size2 = 10  # Number of units in second hidden layer\n",
    "output_size = 3    # Number of output classes\n",
    "print(f' input_size_mnl = {input_size_mnl}, input_size_mlp = {input_size_mlp}, hidden_size1 = {hidden_size1}, hidden_size2 = {hidden_size2}, output_size = {output_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Model Summary ===\n",
      "Layer: B_transport.weight  |\t Weights: 1\n",
      "Layer: B_stores.weight     |\t Weights: 1\n",
      "Layer: linear1.weight      |\t Weights: 150\n",
      "Layer: linear2.weight      |\t Weights: 100\n",
      "Layer: linear3.weight      |\t Weights: 30\n",
      "\n",
      "Total trainable Weights: 282\n",
      "\n",
      "=== Layers ===\n",
      "Linear(in_features=1, out_features=1, bias=False)\n",
      "Linear(in_features=1, out_features=1, bias=False)\n",
      "Linear(in_features=15, out_features=10, bias=False)\n",
      "Linear(in_features=10, out_features=10, bias=False)\n",
      "Linear(in_features=10, out_features=3, bias=False)\n"
     ]
    }
   ],
   "source": [
    "# Invoke the L-MNL model\n",
    "model = LMNL(input_size_mlp, hidden_size1, hidden_size2, output_size)\n",
    "\n",
    "# Print the model architecture\n",
    "print_model_summary(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`v. Train the L-MNL model`<br>\n",
    "Finally, we are ready to train the L-MNL model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training settings\n",
    "nEpoch = 1000  # Set the number of epochs\n",
    "lr = 0.0001  # Set the learning rate\n",
    "status = 10  # Print status every 'status' epochs\n",
    "patience = 5  # Number of epochs to wait before early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [    1/1000], Train Loss: 18899.172, Test Loss: 4486.646\n",
      "Epoch [   10/1000], Train Loss: 17755.680, Test Loss: 4214.775\n",
      "Epoch [   20/1000], Train Loss: 16381.819, Test Loss: 3888.463\n",
      "Epoch [   30/1000], Train Loss: 14791.604, Test Loss: 3516.555\n",
      "Epoch [   40/1000], Train Loss: 13094.006, Test Loss: 3127.099\n",
      "Epoch [   50/1000], Train Loss: 11552.322, Test Loss: 2779.904\n",
      "Epoch [   60/1000], Train Loss: 10372.726, Test Loss: 2518.547\n",
      "Epoch [   70/1000], Train Loss: 9566.876, Test Loss: 2339.590\n",
      "Epoch [   80/1000], Train Loss: 8968.763, Test Loss: 2202.073\n",
      "Epoch [   90/1000], Train Loss: 8458.521, Test Loss: 2080.972\n",
      "Epoch [  100/1000], Train Loss: 8014.899, Test Loss: 1975.034\n",
      "Epoch [  110/1000], Train Loss: 7641.071, Test Loss: 1885.439\n",
      "Epoch [  120/1000], Train Loss: 7329.482, Test Loss: 1809.402\n",
      "Epoch [  130/1000], Train Loss: 7070.422, Test Loss: 1744.449\n",
      "Epoch [  140/1000], Train Loss: 6857.565, Test Loss: 1688.657\n",
      "Epoch [  150/1000], Train Loss: 6684.890, Test Loss: 1641.461\n",
      "Epoch [  160/1000], Train Loss: 6545.663, Test Loss: 1602.595\n",
      "Epoch [  170/1000], Train Loss: 6433.153, Test Loss: 1570.470\n",
      "Epoch [  180/1000], Train Loss: 6342.054, Test Loss: 1544.159\n",
      "Epoch [  190/1000], Train Loss: 6267.831, Test Loss: 1522.531\n",
      "Epoch [  200/1000], Train Loss: 6208.492, Test Loss: 1505.231\n",
      "Epoch [  210/1000], Train Loss: 6161.703, Test Loss: 1491.605\n",
      "Epoch [  220/1000], Train Loss: 6125.964, Test Loss: 1480.977\n",
      "Epoch [  230/1000], Train Loss: 6099.845, Test Loss: 1473.241\n",
      "Epoch [  240/1000], Train Loss: 6080.608, Test Loss: 1467.454\n",
      "Epoch [  250/1000], Train Loss: 6067.145, Test Loss: 1463.331\n",
      "Epoch [  260/1000], Train Loss: 6057.128, Test Loss: 1460.357\n",
      "Epoch [  270/1000], Train Loss: 6049.680, Test Loss: 1458.291\n",
      "Epoch [  280/1000], Train Loss: 6044.079, Test Loss: 1456.836\n",
      "Epoch [  290/1000], Train Loss: 6039.404, Test Loss: 1455.716\n",
      "Epoch [  300/1000], Train Loss: 6035.858, Test Loss: 1455.016\n",
      "Epoch [  310/1000], Train Loss: 6032.284, Test Loss: 1453.995\n",
      "Epoch [  320/1000], Train Loss: 6029.575, Test Loss: 1453.510\n",
      "Epoch [  330/1000], Train Loss: 6026.846, Test Loss: 1452.987\n",
      "Epoch [  340/1000], Train Loss: 6024.580, Test Loss: 1452.690\n",
      "Epoch [  350/1000], Train Loss: 6022.482, Test Loss: 1452.138\n",
      "Epoch [  360/1000], Train Loss: 6020.620, Test Loss: 1452.003\n",
      "Early stopping at epoch 362\n",
      "\n",
      "Training finished.\tTrain Loss: 6019.997, Test Loss: 1451.940\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the loss function and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss(reduction='sum')\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=lr,  betas=(0.9, 0.999), eps=1e-07, weight_decay=0)\n",
    "\n",
    "# Define lists to store losses\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "# Initialize early stopping counter \n",
    "counter = 0\n",
    "best_loss = np.inf  # Set initial loss to infinity\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(nEpoch):\n",
    "    running_loss = 0.0\n",
    "    for x_mnl, x_mlp, labels in train_loader_lmnl:\n",
    "        \n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(x_mnl,x_mlp)   \n",
    "\n",
    "        # Compute the loss\n",
    "        loss = loss_fn(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update running loss\n",
    "        running_loss += loss.item() # Log-likelihood on the training set\n",
    "\n",
    "    # Evaluate on the test set\n",
    "    test_loss = evaluate_lmnl(model, loss_fn, test_loader_lmnl)\n",
    "\n",
    "    # Print status every 'status' epochs or epoch 0\n",
    "    if epoch == 0 or (epoch + 1) % status == 0:\n",
    "        print(f'Epoch [{epoch+1:5.0f}/{nEpoch}], Train Loss: {running_loss:0.3f}, Test Loss: {test_loss:0.3f}')\n",
    "\n",
    "    # Store losses\n",
    "    train_losses.append(running_loss)\n",
    "    test_losses.append(test_loss)\n",
    "\n",
    "    # Implement early stopping\n",
    "    if test_loss < best_loss:\n",
    "        best_loss = test_loss\n",
    "        counter = 0\n",
    "    else:\n",
    "        counter += 1\n",
    "        if counter >= patience:\n",
    "            print(f'Early stopping at epoch {epoch+1}')\n",
    "            break\n",
    "        \n",
    "print(f'\\nTraining finished.\\tTrain Loss: {running_loss:0.3f}, Test Loss: {test_loss:0.3f}')\n",
    "show_loss_plot(train_losses, test_losses, num_obs_train, num_obs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Willingness to pay to reduce one minute of walking time to the grocery store is: 0.45 walking minutes to the public transport\n"
     ]
    }
   ],
   "source": [
    "# Compute the Willingness to pay to reduce the distance to the grovery store by one minute\n",
    "LL_LMNL = best_loss\n",
    "B_transport_LMNL = model.B_transport.weight.data.item()\n",
    "B_stores_LMNL = model.B_stores.weight.data.item()\n",
    "\n",
    "WTP_LMNL = B_stores_LMNL/B_transport_LMNL\n",
    "print(f'\\nWillingness to pay to reduce one minute of walking time to the grocery store is: {WTP_LMNL:.2f} walking minutes to the public transport')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Reflections`\n",
    "1. The L-MNL model attains a model fit that is very close to the fully flexible MLP model\n",
    "1. The L-MNL model gives insight into the trade-off between distance to the grocery stores and distance to the public transport\n",
    "1. The results recovered WTP is not stable, it fluctuates over runs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Exercise 4: Features MLP`<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`A` Try reducing the number of features that are fed into the MLP and assess the impact on the model performance and WTP. <br>\n",
    "That is, use only `RESPCITY` and `WOMAN`<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{green}{\\text{Add your answers here}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWERS\n",
    "do_exercise4 = False\n",
    "if do_exercise4 == True:\n",
    "    #### Recreate tensors for the train set ####\n",
    "\n",
    "    #In this case, we only have to modify the variables that will go into the MLP model:    \n",
    "    features_socio = ['WOMAN_1', 'RESPCITY_2', 'RESPCITY_3', 'RESPCITY_4']\n",
    "\n",
    "    x_mlp_train = x_train_scaled[features_mlp_alt + features_socio]\n",
    "    x_mlp_test  = x_test_scaled[features_mlp_alt + features_socio]\n",
    "    \n",
    "    x_mlp_train_tensor = torch.tensor(x_mlp_train.values, dtype=torch.float)\n",
    "    x_mlp_test_tensor = torch.tensor(x_mlp_test.values, dtype=torch.float)\n",
    "    \n",
    "\n",
    "    #### Recreate DataLoader ####\n",
    "    dataset_train_lmnl = TensorDataset(x_mnl_train_tensor, x_mlp_train_tensor, y_train_dummy_tensor)\n",
    "    train_loader_lmnl = DataLoader(dataset_train_lmnl, batch_size=250, shuffle=True)\n",
    "    dataset_test_lmnl = TensorDataset(x_mnl_test_tensor, x_mlp_test_tensor, y_test_dummy_tensor)\n",
    "    test_loader_lmnl = DataLoader(dataset_test_lmnl, batch_size=len(x_test_tensor), shuffle=False)\n",
    "\n",
    "\n",
    "    #### Redefine the dimension of the MLP  ####\n",
    "    input_size_mlp = x_mlp_train_tensor.size()[1]  # Number of input features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`A.ii` Retrain the MLP model using the same cell as above:  <br>\n",
    "\n",
    "Train Loss: 6019.589, Test Loss: 1378.459 and the Willingness to pay to reduce one minute of walking time to the grocery store is: 1.02 walking minutes to the public transport"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Exercise 5: Forecasting using L-MNL`<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A researcher would like to use this model to make market share predictions. However, this is more challenging.<br>\n",
    "\n",
    "`A` Give 2 reasons why making forecasts using the L-MNL model is less straightforward than using the MNL models<br>\n",
    "`B` Give 2 arguments in favour of using the L-MNL model for informing policy making.<br>\n",
    "`C` Suppose that you are hired to assist and advise this researcher. What would you advise in terms of e.g. the specification of the L-MNL model, training, benchmarking, etc.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{green}{\\text{Add your answers here}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`A` <br>\n",
    "(1) The model makes different forecasts everytime we train it. To account for this, the researcher probably want to train numerous models and average the forecasts.<br>\n",
    "(2) In case socio-demographic variables are used, the predictions of the L-MNL model are conditional on the socio-demographic variables. In case the sample of skewed (e.g. too many females/young people, etc. it is not clear how to correct for this)<br>\n",
    "(3) Training times and data preprocessing are more time consuming and laborious<br>\n",
    "(4) The model is less easy to explain to layment than a simple MNL model. This makes adoption of the results less likely. e.g. policy makers are reluctant to base decisions on models they do not understand.<br>\n",
    "\n",
    "`B` <br>\n",
    "(1) Empirically, the L-MNL model is found to attain a considerbly better model fit. This means that the model is able to better replicate the choce behaviour, and corollary, the forecasts are more accurate.<br>\n",
    "(2) Conceptually, the linear-additive MNL model is too simplistic to captures the complexities of real human choice behaviour.<br>\n",
    "\n",
    "`C` \n",
    "- Use the MNL model to test expected interactions/nonlinearities\n",
    "- Test numerous specifications for the L-MNL, in terms of features. \n",
    "- Evaluate the specification in terms of fit, but also in terms of implied WTPs. \n",
    "- Conduct a proper hyperparameter tuning\n",
    "- Always benchmark/compare the results against the RUM-MNL. \n",
    "- Account for the stochasticity of the L-MNL model through averaging across numerous runs. \n",
    "- Ideally, new data would be collected, specifically for Zurich, that better takes into account the attributes of neighbourhoods beyond the ones used in the current SC experiment.\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "570feb405e2e27c949193ac68f46852414290d515b0ba6e5d90d076ed2284471"
  },
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
