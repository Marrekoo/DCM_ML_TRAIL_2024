{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discrete Choice Analysis: micro-econometrics and machine learning approaches\n",
    "\n",
    "## `Lab session 1: Artificial Neural Networks`\n",
    "\n",
    "**Delft University of Technology**<br>\n",
    "**February 2024**<br>\n",
    "**Instructor:** Sander van Cranenburgh <br>\n",
    "**TAs:**  Gabriel Nova <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Instructions`\n",
    "\n",
    "**Lab sessions aim to:**<br>\n",
    "* Illustrate how models and theory discussed in the classroom work out in practice.\n",
    "* Help you gather hands-on modelling and data analysis skills.\n",
    "\n",
    "**Lab sessions are:**<br>\n",
    "* Learning environments where you work with Jupyter notebooks and where you can get support from TAs and fellow students.<br> \n",
    "* Not graded and do not have to be submitted. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Workspace set-up`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Option 1: Local environment**<br>\n",
    "Uncomment the following cell if you are running this notebook on your local environment, to install all dependencies on your Python version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Option 2: Google Colab**<br>\n",
    "Uncomment the following cell if you are running this notebook on Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!git clone https://github.com/DCM-ML-course-TRAIL/DCM_ML_TRAIL_2024\n",
    "#!pip install -r DCM_ML_TRAIL_2024/requirements_colab.txt\n",
    "#!mv \"/content/DCM_ML_TRAIL_2024/Lab sessions/data\" /content/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Application: Modelling mode choices` <br>\n",
    "In this lab session, we will analyse mode choice behaviour. Understanding people's preferences over transport attributes is crucial for city planners when they (re)develop  devise policies to enhance sustainable urban mobility. During this lab session, you will apply discrete choice models to uncover people's preferences over attributes, such as the travel time, travel cost, access time, and level of service. Also, you will explore whether preferences interact with covariates such as female, business, income. While doing so, you will test various utility specifications and interpret the modelling outcomes of discrete choice models.\n",
    "\n",
    "For this study, we use data from a Stated Choice (SC) experiment provided by [Apollo](https://www.apollochoicemodelling.com/examples.html)\n",
    "\n",
    "**`Learning objectives lab session 01`**\n",
    "\n",
    "After completing the following exercises you will be able to: <br>\n",
    "* Prepare (choice) data for training Artificial Neural Networks\n",
    "* Train MultiLayerPerceptron (MLP) - a praticular type of neural network - for a classification task<br>\n",
    "* Tune the hyperparameter and network architectures to improve the model performance<br>\n",
    "* Assess the performance of of competing models, based on various performance measures, including confusion matrices, and Precision, Recall, F1 scores and Matthew's coefficient<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`This lab consists of 6 parts`**\n",
    "1. Preparing (choice) data for training Artificial Neural Networks\n",
    "2. Training a MultiLayerPerceptron (MLP) neural network\n",
    "3. Using Early stopping to avoid overfitting\n",
    "4. Using k-fold cross validation to evaluate generalisation performance\n",
    "5. Tuning hyperparameter\n",
    "6. Evaluating performance of trained models\n",
    "\n",
    "and comprises **`7`** exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Import packages`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin, we will import all the Python libraries that we will use in this lab session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required Python packages and modules\n",
    "import os\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "# Import selected functions and classes from Python packages\n",
    "from os import getcwd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_validate\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, log_loss, matthews_corrcoef, make_scorer, classification_report\n",
    "\n",
    "# Biogeme\n",
    "import biogeme.database as db\n",
    "import biogeme.biogeme as bio\n",
    "from biogeme import models\n",
    "from biogeme.expressions import Beta, Variable, log\n",
    "\n",
    "# Setting\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `0. Preparing (choice) data for training Artificial Neural Networks`\n",
    "To prepare the data set, we will:<br>\n",
    "    1.1 **Load** the data set<br>\n",
    "    1.2 **Inspect** and **Clean** the data set<br>\n",
    "    1.3 **Discover and visualise** the data <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " `i. Set up the workspace and load the database`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/apollo_modeChoiceData.csv\n"
     ]
    }
   ],
   "source": [
    "# Get the current working directory\n",
    "data_path =  Path(f'data/apollo_modeChoiceData.csv')\n",
    "print(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7000, 26)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load mode choice data into a pandas DataFrame\n",
    "df = pd.read_csv(data_path,sep = ',')\n",
    "df = df[df['SP']==1]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inspect and clean the data**<br>\n",
    "Before starting to analyse your data, make sure you understand what features are in your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>RP</th>\n",
       "      <th>SP</th>\n",
       "      <th>RP_journey</th>\n",
       "      <th>SP_task</th>\n",
       "      <th>av_car</th>\n",
       "      <th>av_bus</th>\n",
       "      <th>av_air</th>\n",
       "      <th>av_rail</th>\n",
       "      <th>time_car</th>\n",
       "      <th>cost_car</th>\n",
       "      <th>time_bus</th>\n",
       "      <th>cost_bus</th>\n",
       "      <th>access_bus</th>\n",
       "      <th>time_air</th>\n",
       "      <th>cost_air</th>\n",
       "      <th>access_air</th>\n",
       "      <th>service_air</th>\n",
       "      <th>time_rail</th>\n",
       "      <th>cost_rail</th>\n",
       "      <th>access_rail</th>\n",
       "      <th>service_rail</th>\n",
       "      <th>female</th>\n",
       "      <th>business</th>\n",
       "      <th>income</th>\n",
       "      <th>choice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>55</td>\n",
       "      <td>3</td>\n",
       "      <td>170</td>\n",
       "      <td>35</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46705</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>65</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>75</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46705</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>110</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>155</td>\n",
       "      <td>75</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46705</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>80</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>170</td>\n",
       "      <td>35</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46705</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>80</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>75</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46705</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  RP  SP  RP_journey  SP_task  av_car  av_bus  av_air  av_rail  time_car  \\\n",
       "2   1   0   1         NaN      1.0       0       0       1        1         0   \n",
       "3   1   0   1         NaN      2.0       0       0       1        1         0   \n",
       "4   1   0   1         NaN      3.0       0       0       1        1         0   \n",
       "5   1   0   1         NaN      4.0       0       0       1        1         0   \n",
       "6   1   0   1         NaN      5.0       0       0       1        1         0   \n",
       "\n",
       "   cost_car  time_bus  cost_bus  access_bus  time_air  cost_air  access_air  \\\n",
       "2         0         0         0           0        50        50          55   \n",
       "3         0         0         0           0        90        65          45   \n",
       "4         0         0         0           0        70       110          40   \n",
       "5         0         0         0           0        90        80          40   \n",
       "6         0         0         0           0        90        80          35   \n",
       "\n",
       "   service_air  time_rail  cost_rail  access_rail  service_rail  female  \\\n",
       "2            3        170         35            5             2       0   \n",
       "3            1        120         75            5             3       0   \n",
       "4            1        155         75           25             2       0   \n",
       "5            1        170         35           25             2       0   \n",
       "6            2        130         75           25             2       0   \n",
       "\n",
       "   business  income  choice  \n",
       "2         0   46705       4  \n",
       "3         0   46705       4  \n",
       "4         0   46705       4  \n",
       "5         0   46705       4  \n",
       "6         0   46705       3  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Description of variables**<br>\n",
    "\n",
    "Therefore, it is highly recommended to look at the description of the data set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Variable       | Description                                           | Values                                                |\n",
    "|----------------|-------------------------------------------------------|-------------------------------------------------------|\n",
    "| ID             | Unique individual ID                                  | 1 to 500                                              |\n",
    "| RP             | RP data identifier                                   | 1 for RP, 0 for SP                                    |\n",
    "| SP             | SP data identifier                                   | 1 for SP, 0 for RP                                    |\n",
    "| RP_journey     | Index for RP observations                             | 1 to 2, NA for SP                                     |\n",
    "| SP_task        | Index for SP observations                             | 1 to 14, NA for RP                                    |\n",
    "| av_car         | Availability for alternative 1 (car)                 | 1 for available, 0 for unavailable                    |\n",
    "| av_bus         | Availability for alternative 2 (bus)                 | 1 for available, 0 for unavailable                    |\n",
    "| av_air         | Availability for alternative 3 (air)                 | 1 for available, 0 for unavailable                    |\n",
    "| av_rail        | Availability for alternative 4 (rail)                | 1 for available, 0 for unavailable                    |\n",
    "| time_car       | Travel time (mins) for alternative 1 (car)           | Min: 250, mean: 311.79, max: 390 (0 if not available) |\n",
    "| cost_car       | Travel cost (£) for alternative 1 (car)              | Min: 30, mean: 39.99, max: 50 (0 if not available)    |\n",
    "| time_bus       | Travel time (mins) for alternative 2 (bus)           | Min: 300, mean: 370.29, max: 420 (0 if not available) |\n",
    "| cost_bus       | Travel cost (£) for alternative 2 (bus)              | Min: 15, mean: 25.02, max: 35 (0 if not available)    |\n",
    "| access_bus     | Access time (mins) for alternative 2 (bus)           | Min: 5, mean: 15.02, max: 25 (0 if not available)      |\n",
    "| time_air       | Travel time (mins) for alternative 3 (air)           | Min: 50, mean: 70.07, max: 90 (0 if not available)    |\n",
    "| cost_air       | Travel cost (£) for alternative 3 (air)              | Min: 50, mean: 79.94, max: 110 (0 if not available)   |\n",
    "| access_air     | Access time (mins) for alternative 3 (air)           | Min: 35, mean: 45.02, max: 55 (0 if not available)    |\n",
    "| service_air    | Service quality for alternative 3 (air)              | 1 for no-frills, 2 for wifi, 3 for food (0 if not used, RP data) |\n",
    "| time_rail      | Travel time (mins) for alternative 4 (rail)          | Min: 120, mean: 142.93, max: 170 (0 if not available) |\n",
    "| cost_rail      | Travel cost (£) for alternative 4 (rail)             | Min: 35, mean: 55.03, max: 75 (0 if not available)    |\n",
    "| access_rail    | Access time (mins) for alternative 4 (rail)          | Min: 5, mean: 14.96, max: 25 (0 if not available)      |\n",
    "| service_rail   | Service quality for alternative 4 (rail)             | 1 for no-frills, 2 for wifi, 3 for food (0 if not used, RP data) |\n",
    "| female         | Dummy variable for female individuals                | 1 for female, 0 otherwise                            |\n",
    "| business       | Dummy variable for business trips                    | 1 for business trips, 0 otherwise                     |\n",
    "| income         | Income variable (£ per annum)                        | Min: 15,490, mean: 44,748.27, max: 74,891              |\n",
    "| choice         | Choice variable                                     | 1 for car, 2 for bus, 3 for air, 4 for rail            |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Descriptive statistics`**<br>\n",
    "\n",
    "We can use `describe()` to view descriptive statistics, such as count, mean, std, min, percentiles, and max about the **attribute levels** of the alternatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7000, 23)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>SP_task</th>\n",
       "      <th>time_car</th>\n",
       "      <th>cost_car</th>\n",
       "      <th>time_bus</th>\n",
       "      <th>cost_bus</th>\n",
       "      <th>access_bus</th>\n",
       "      <th>time_air</th>\n",
       "      <th>cost_air</th>\n",
       "      <th>access_air</th>\n",
       "      <th>service_air</th>\n",
       "      <th>time_rail</th>\n",
       "      <th>cost_rail</th>\n",
       "      <th>access_rail</th>\n",
       "      <th>service_rail</th>\n",
       "      <th>female</th>\n",
       "      <th>business</th>\n",
       "      <th>income</th>\n",
       "      <th>av_car</th>\n",
       "      <th>av_bus</th>\n",
       "      <th>av_rail</th>\n",
       "      <th>av_air</th>\n",
       "      <th>choice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7000.00000</td>\n",
       "      <td>7000.000000</td>\n",
       "      <td>7000.000000</td>\n",
       "      <td>7000.000000</td>\n",
       "      <td>7000.000000</td>\n",
       "      <td>7000.000000</td>\n",
       "      <td>7000.000000</td>\n",
       "      <td>7000.000000</td>\n",
       "      <td>7000.000000</td>\n",
       "      <td>7000.000000</td>\n",
       "      <td>7000.000000</td>\n",
       "      <td>7000.000000</td>\n",
       "      <td>7000.000000</td>\n",
       "      <td>7000.000000</td>\n",
       "      <td>7000.000000</td>\n",
       "      <td>7000.000000</td>\n",
       "      <td>7000.000000</td>\n",
       "      <td>7000.000000</td>\n",
       "      <td>7000.000000</td>\n",
       "      <td>7000.000000</td>\n",
       "      <td>7000.000000</td>\n",
       "      <td>7000.000000</td>\n",
       "      <td>7000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>250.50000</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>243.037143</td>\n",
       "      <td>31.080714</td>\n",
       "      <td>334.084286</td>\n",
       "      <td>22.577143</td>\n",
       "      <td>13.576429</td>\n",
       "      <td>52.704286</td>\n",
       "      <td>60.082857</td>\n",
       "      <td>33.831429</td>\n",
       "      <td>1.500857</td>\n",
       "      <td>124.950000</td>\n",
       "      <td>48.015714</td>\n",
       "      <td>13.079286</td>\n",
       "      <td>1.741429</td>\n",
       "      <td>0.476000</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>44748.274000</td>\n",
       "      <td>0.778000</td>\n",
       "      <td>0.902000</td>\n",
       "      <td>0.874000</td>\n",
       "      <td>0.752000</td>\n",
       "      <td>2.846286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>144.34759</td>\n",
       "      <td>4.031417</td>\n",
       "      <td>137.206105</td>\n",
       "      <td>17.735009</td>\n",
       "      <td>115.666923</td>\n",
       "      <td>10.034647</td>\n",
       "      <td>8.070708</td>\n",
       "      <td>32.667098</td>\n",
       "      <td>39.177958</td>\n",
       "      <td>20.381387</td>\n",
       "      <td>1.115555</td>\n",
       "      <td>50.293655</td>\n",
       "      <td>22.516328</td>\n",
       "      <td>8.264116</td>\n",
       "      <td>1.012565</td>\n",
       "      <td>0.499459</td>\n",
       "      <td>0.470246</td>\n",
       "      <td>17060.095215</td>\n",
       "      <td>0.415621</td>\n",
       "      <td>0.297336</td>\n",
       "      <td>0.331873</td>\n",
       "      <td>0.431883</td>\n",
       "      <td>1.262209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15490.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>125.75000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30371.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>250.50000</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>275.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>44977.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>375.25000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>345.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>390.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>59155.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>500.00000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>390.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>420.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>170.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>74891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ID      SP_task     time_car     cost_car     time_bus  \\\n",
       "count  7000.00000  7000.000000  7000.000000  7000.000000  7000.000000   \n",
       "mean    250.50000     7.500000   243.037143    31.080714   334.084286   \n",
       "std     144.34759     4.031417   137.206105    17.735009   115.666923   \n",
       "min       1.00000     1.000000     0.000000     0.000000     0.000000   \n",
       "25%     125.75000     4.000000   250.000000    30.000000   330.000000   \n",
       "50%     250.50000     7.500000   275.000000    35.000000   360.000000   \n",
       "75%     375.25000    11.000000   345.000000    45.000000   390.000000   \n",
       "max     500.00000    14.000000   390.000000    50.000000   420.000000   \n",
       "\n",
       "          cost_bus   access_bus     time_air     cost_air   access_air  \\\n",
       "count  7000.000000  7000.000000  7000.000000  7000.000000  7000.000000   \n",
       "mean     22.577143    13.576429    52.704286    60.082857    33.831429   \n",
       "std      10.034647     8.070708    32.667098    39.177958    20.381387   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%      15.000000     5.000000    50.000000    50.000000    35.000000   \n",
       "50%      25.000000    15.000000    60.000000    65.000000    40.000000   \n",
       "75%      30.000000    20.000000    80.000000    95.000000    50.000000   \n",
       "max      35.000000    25.000000    90.000000   110.000000    55.000000   \n",
       "\n",
       "       service_air    time_rail    cost_rail  access_rail  service_rail  \\\n",
       "count  7000.000000  7000.000000  7000.000000  7000.000000   7000.000000   \n",
       "mean      1.500857   124.950000    48.015714    13.079286      1.741429   \n",
       "std       1.115555    50.293655    22.516328     8.264116      1.012565   \n",
       "min       0.000000     0.000000     0.000000     0.000000      0.000000   \n",
       "25%       1.000000   120.000000    35.000000     5.000000      1.000000   \n",
       "50%       1.000000   140.000000    55.000000    15.000000      2.000000   \n",
       "75%       2.000000   155.000000    65.000000    20.000000      3.000000   \n",
       "max       3.000000   170.000000    75.000000    25.000000      3.000000   \n",
       "\n",
       "            female     business        income       av_car       av_bus  \\\n",
       "count  7000.000000  7000.000000   7000.000000  7000.000000  7000.000000   \n",
       "mean      0.476000     0.330000  44748.274000     0.778000     0.902000   \n",
       "std       0.499459     0.470246  17060.095215     0.415621     0.297336   \n",
       "min       0.000000     0.000000  15490.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000  30371.500000     1.000000     1.000000   \n",
       "50%       0.000000     0.000000  44977.000000     1.000000     1.000000   \n",
       "75%       1.000000     1.000000  59155.500000     1.000000     1.000000   \n",
       "max       1.000000     1.000000  74891.000000     1.000000     1.000000   \n",
       "\n",
       "           av_rail       av_air       choice  \n",
       "count  7000.000000  7000.000000  7000.000000  \n",
       "mean      0.874000     0.752000     2.846286  \n",
       "std       0.331873     0.431883     1.262209  \n",
       "min       0.000000     0.000000     1.000000  \n",
       "25%       1.000000     1.000000     1.000000  \n",
       "50%       1.000000     1.000000     3.000000  \n",
       "75%       1.000000     1.000000     4.000000  \n",
       "max       1.000000     1.000000     4.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data cleaning\n",
    "\n",
    "# list of relevant features\n",
    "id         = ['ID', 'SP_task' ] \n",
    "\n",
    "# Attributes\n",
    "attributes =   ['time_car',  'cost_car', \n",
    "                'time_bus',  'cost_bus',  'access_bus',\n",
    "                'time_air',  'cost_air',  'access_air',  'service_air', \n",
    "                'time_rail', 'cost_rail', 'access_rail', 'service_rail']\n",
    "\n",
    "# Socio-demographic variables\n",
    "sociovars = ['female', 'business','income']\n",
    "\n",
    "# Availability variables\n",
    "av = ['av_car', 'av_bus', 'av_rail', 'av_air']\n",
    "\n",
    "# Create a new instance of the dataframe, with the atrtributes, socio-demographic variables and the choice\n",
    "dff = df[id + attributes + sociovars + av +['choice'] ].copy()\n",
    "\n",
    "print(dff.shape)\n",
    "dff.describe()\n",
    "\n",
    "# Inspect the data types in the df\n",
    "# df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discovering and visualising the data**<br>\n",
    "Before starting to analyse your data with models, it is advisable to start with some **descriptive analyses**.<br>\n",
    "Therefore is recommended to look first at the distribution and correlations of key feature in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ``Exercise 1: Is the data set (im)balanced?``\n",
    "`A` Create a histogram showing how often TRAIN, SM and CAR are chosen. Do not forget to add labels to the columns<br>\n",
    "`B` Interpret the the histogram. Is the data set imbalanced? <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{green}{\\text{Add your answers here}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWERS\n",
    "# A) \n",
    "# B) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ``Exercise 2: Explore correlations between features``\n",
    "`A` Create a heatmap to identify what features particulalrly correlate with the **CHOICE**<br>\n",
    "`B` Identify the features that strongly correlate (corr >0.9) (if any). Do they make sense? <br>\n",
    "Hint: to do so you will need the description of the features [Click here](https://github.com/TPM34A/Admin_2022/blob/main/lab%20sessions/lab_ex02/data/CS_SwissmetroDescription.pdf) to open the pdf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{green}{\\text{Add your answers here}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWERS\n",
    "# A) \n",
    "# B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `1. Estimate benchmark discrete choice model`<br>\n",
    "As a benchmark, we use the linear-additive RUM model model. We estimate this model using `biogeme`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert pandas dff into biogeme database\n",
    "biodata = db.Database('neighbourhood_data_train', dff)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Biogeme variables\n",
    "\n",
    "# Attributes of alternative 1\n",
    "time_car     = Variable('time_car')\n",
    "cost_car     = Variable('cost_car')\n",
    "\n",
    "# Attributes of alternative 2    \n",
    "time_bus     = Variable('time_bus')\n",
    "cost_bus     = Variable('cost_bus')\n",
    "access_bus   = Variable('access_bus')\n",
    "    \n",
    "# Attributes of alternative 3\n",
    "time_air     = Variable('time_air')\n",
    "cost_air     = Variable('cost_air')\n",
    "access_air   = Variable('access_air')\n",
    "service_air  = Variable('service_air')\n",
    "\n",
    "# Attributes of alternative 4\n",
    "time_rail     = Variable('time_rail')\n",
    "cost_rail     = Variable('cost_rail')\n",
    "access_rail   = Variable('access_rail')\n",
    "service_rail  = Variable('service_rail')\n",
    "\n",
    "# Availability variables\n",
    "av_car       = Variable('av_car')\n",
    "av_bus       = Variable('av_bus')\n",
    "av_rail      = Variable('av_rail')\n",
    "av_air       = Variable('av_air')\n",
    "\n",
    "# choice\n",
    "choice      = Variable('choice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model Linear-additive RUM-MNL\n",
      "Nbr of parameters:\t\t8\n",
      "Sample size:\t\t\t7000\n",
      "Excluded data:\t\t\t0\n",
      "Null log likelihood:\t\t-8196.021\n",
      "Final log likelihood:\t\t-5761.741\n",
      "Likelihood ratio test (null):\t\t4868.56\n",
      "Rho square (null):\t\t\t0.297\n",
      "Rho bar square (null):\t\t\t0.296\n",
      "Akaike Information Criterion:\t11539.48\n",
      "Bayesian Information Criterion:\t11594.31\n",
      "\n",
      "              Value  Rob. Std err  Rob. t-test  Rob. p-value\n",
      "ASC_air    0.435186      0.111649     3.897810  9.706658e-05\n",
      "ASC_bus   -1.310174      0.092126   -14.221604  0.000000e+00\n",
      "ASC_car    0.740550      0.073947    10.014667  0.000000e+00\n",
      "ASC_rail   0.134437      0.055442     2.424810  1.531641e-02\n",
      "B_access  -0.018790      0.002462    -7.633456  2.287059e-14\n",
      "B_cost    -0.055508      0.001467   -37.836987  0.000000e+00\n",
      "B_service  0.182630      0.023526     7.762813  8.215650e-15\n",
      "B_time    -0.010633      0.000550   -19.338157  0.000000e+00\n"
     ]
    }
   ],
   "source": [
    "# Give a name to the model    \n",
    "model_name = 'Linear-additive RUM-MNL'\n",
    "\n",
    "# Define the model parameters, using the function \"Beta()\", in which you must define:\n",
    "B_time        = Beta('B_time',      0, None, None, 0)\n",
    "B_cost        = Beta('B_cost',      0, None, None, 0)\n",
    "B_access      = Beta('B_access',    0, None, None, 0)\n",
    "B_service     = Beta('B_service',   0, None, None, 0)\n",
    "ASC_car       = Beta('ASC_car',     0, None, None, 0)\n",
    "ASC_bus       = Beta('ASC_bus',     0, None, None, 0)\n",
    "ASC_air       = Beta('ASC_air',     0, None, None, 0)\n",
    "ASC_rail      = Beta('ASC_rail',    0, None, None, 0)\n",
    "\n",
    "# Define the utility functions\n",
    "V1 = ASC_car + B_time * time_car   + B_cost * cost_car\n",
    "V2 = ASC_bus + B_time * time_bus   + B_cost * cost_bus  + B_access * access_bus\n",
    "V3 = ASC_air + B_time * time_air   + B_cost * cost_air  + B_access * access_air  + B_service * service_air\n",
    "V4 = ASC_rail + B_time * time_rail + B_cost * cost_rail + B_access * access_rail + B_service * service_rail\n",
    "\n",
    "# Associate utility functions with alternatives\n",
    "V = {1: V1, 2: V2, 3: V3, 4: V4}    \n",
    "\n",
    "# Associate the availability conditions with the alternatives\n",
    "AV = {1: av_car, 2: av_bus, 3: av_air, 4: av_rail} \n",
    "\n",
    "# Definition of the model. This is the contribution of each observation to the log likelihood function.\n",
    "prob = models.logit(V, AV, choice)\n",
    "\n",
    "# Create the Biogeme object\n",
    "biogeme = bio.BIOGEME(biodata, log(prob))\n",
    "\n",
    "# Set reporting levels\n",
    "biogeme.generate_pickle = False\n",
    "biogeme.generate_html = False\n",
    "biogeme.saveIterations = False\n",
    "biogeme.modelName = model_name\n",
    "\n",
    "# Compute the null loglikelihood for reporting\n",
    "biogeme.calculateNullLoglikelihood(AV)\n",
    "\n",
    "# Estimate the parameters\n",
    "results_rum_mnl = biogeme.estimate()\n",
    "print(results_rum_mnl.short_summary())\n",
    "\n",
    "# Get the results in a pandas table\n",
    "beta_hat = results_rum_mnl.getEstimatedParameters()\n",
    "print(beta_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `2. Training a MultiLayerPerceptron (MLP) neural network`\n",
    "To train Artifical Neural Networks we take the following steps:<br>\n",
    "    2.1 **Scaling** the features<br>\n",
    "    2.2 **Splitting** the data in a training and test data set<br>\n",
    "    2.3 **Creating MLP** object<br>\n",
    "    2.4 **Training the MLP** on the train data<br>\n",
    "    2.5 **Evaluating** the performance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`i. Scaling the features`<br>\n",
    "To efficiently train ANNs it strongly recommended to **scale** (a.k.a. normalise) the features. There are several ways to scale your data. A commonly used scaler of `sk-learn` is called 'StandardScaler'. This scaler normalises the variance and shift the location of the distribution to zero, see https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates the list of features that need to be scaled\n",
    "# Importantly, this excludes the availabilities and the choice\n",
    "features2scale = attributes + sociovars \n",
    "\n",
    "# Initiate scaler object & fit to data\n",
    "scaler = StandardScaler()  \n",
    "dff_scaled_f = scaler.fit_transform(dff.loc[:,features2scale]) \n",
    "dff_scaled_f = pd.DataFrame(dff_scaled_f, columns = features2scale) \n",
    "dff_scaled_f.reset_index(drop=True, inplace=True)  # Reset indices\n",
    "\n",
    "# Create new dataframe X_scaled containingg the scaled features AND the (unscaled) ones: Group, Survey, Choice\n",
    "dff_scaled = dff.copy()\n",
    "dff_scaled.reset_index(drop=True, inplace=True)\n",
    "dff_scaled[features2scale] = dff_scaled_f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ii. Splitting the data in a train set and a test set`<br>\n",
    "Training ML models always involves a **train** and a **test** data set. The train set is used to update the weights of the model. Tha test set is used to evaluate the **generalisation performance** of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the list of features that we want to use in the model\n",
    "features = attributes + sociovars + av\n",
    "\n",
    "# Create the target\n",
    "Y = dff_scaled['choice']\n",
    "\n",
    "# Split the data using sk-learn's `train_test_split` function\n",
    "# Note that we use 60% for training and 40% for testing\n",
    "# Note that we set the random_state, in order to replicate results later (do not change) \n",
    "X_train, X_test, Y_train, Y_test = train_test_split(dff_scaled[features], Y, random_state = 12345, test_size = 0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`iii. Creating the MLP object`<br>\n",
    "A MultiLayerPerceptron (MLP) is a fully-connected feed-forward neural network. We create the MLP using `sk-learn's` MLPClassifier function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 'plain vanilla' MLP object\n",
    "# Declare the number of layers and nodes per layer\n",
    "# layers = (a,b) means two layer with a nodes in the 1st hidden layer and b nodes in the 2nd hidden layer\n",
    "layers = (10)\n",
    "\n",
    "# Define MLP architecture, optimiser and hyperparameters:\n",
    "# We use Adam optimiser\n",
    "# We use the learning rate to 0.001\n",
    "# We use L2 regularisation of 0\n",
    "# We use a batch size of 250 observations\n",
    "# We use relu activation (transfer function)\n",
    "# We set the max number of epochs to 2000\n",
    "mlp = MLPClassifier(hidden_layer_sizes = layers, solver='adam', learning_rate_init = 0.001, alpha=0, batch_size=250, activation = 'relu', max_iter = 2000) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`iv. Training the MLP`<br>\n",
    "To train the MLP we use the '.fit' function.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(alpha=0, batch_size=250, hidden_layer_sizes=10, max_iter=2000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(alpha=0, batch_size=250, hidden_layer_sizes=10, max_iter=2000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(alpha=0, batch_size=250, hidden_layer_sizes=10, max_iter=2000)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the MLP using the train data.\n",
    "mlp.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Cross entropy loss on the TRAINING DATA. \\nBest CE = 0.674')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# It is good practice to look at the learning curve, to see how much the model has improved from the initial point,\n",
    "# and how is has evolved over epochs.\n",
    "fig, ax = plt.subplots(figsize = (16,8))\n",
    "plt.plot(mlp.loss_curve_)\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Cross entropy loss')\n",
    "ax.grid(True,linewidth = 0.5)\n",
    "ax.set_ylim(0.0,1.2)\n",
    "ax.set_xlim(0,mlp.n_iter_)\n",
    "ax.set_title(f'Cross entropy loss on the TRAINING DATA. \\nBest CE = {mlp.loss_:4.3f}')\n",
    "# The plot illustrates that the training stops when the training loss does no longer improve more that a given tolerance (e.g. 1e-6), or reaches max_iter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`v. Evaluating the model performance` <br>\n",
    "Machine learning researchers usually evaluate the performance of a classification model using the cross-entropy. A lower cross entrop indicates a better model. In contrast, choice modellers usually look at the Log-likelihood (LL) and the rho-square. A high LL and rho-square indicate a better model. <br>\n",
    "As there is no standard function that outputs the evaluation metrics of both disciplines, below we create our **own evaluation function**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create an eavluation function that returns key evaluation metrics: LL, LL0, cross_entropy, rho_sq\n",
    "# To compute these performance metrics, the function takes as inputs:\n",
    "#   - the predicted probabilities (prob)\n",
    "#   - the choices (Y)\n",
    "#   - the availabilities (AV)\n",
    "def eval_performance(prob,Y,AV):\n",
    "    \n",
    "    # Calculate the likelihood of the data given the model\n",
    "    LL = np.sum(np.log(np.sum(prob*Y,axis=1)))\n",
    "\n",
    "    # Calculate the Null-loglikelihood\n",
    "    LL0 = np.sum(np.log(np.divide(1,np.sum(AV,axis=1))))\n",
    "\n",
    "    # Calculate cross-entropy\n",
    "    cross_entropy =  -LL/len(AV)\n",
    "    \n",
    "    # Calculate the rho_sq\n",
    "    rho_sq = 1 -(LL/LL0)\n",
    "    return LL, LL0, cross_entropy, rho_sq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model performance of the plain vanilla MLP:\n",
      "                      0         1\n",
      "data set          Train      Test\n",
      "LL            -2,824.31 -2,014.52\n",
      "LL0           -4,902.96 -3,293.06\n",
      "cross_entropy      0.67      0.72\n",
      "rho_sq             0.42      0.39\n"
     ]
    }
   ],
   "source": [
    "# Let's use our function to evaluate and compare the performance of our MLP on the training and test data sets\n",
    "eval_train = eval_performance(mlp.predict_proba(X_train),np.transpose([Y_train ==1,Y_train ==2,Y_train ==3, Y_train ==4]), X_train[['av_car','av_bus','av_rail','av_air']])\n",
    "eval_test  = eval_performance(mlp.predict_proba(X_test), np.transpose([Y_test  ==1,Y_test  ==2,Y_test  ==3, Y_test  ==4]), X_test[['av_car','av_bus','av_rail','av_air']])\n",
    "\n",
    "# Print the results\n",
    "print('Model performance of the plain vanilla MLP:')\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "results = pd.DataFrame({'data set':     ['Train','Test'],\n",
    "                        'LL':           [eval_train[0], eval_test[0]],\n",
    "                        'LL0':          [eval_train[1], eval_test[1]],\n",
    "                        'cross_entropy':[eval_train[2], eval_test[2]],\n",
    "                        'rho_sq':       [eval_train[3], eval_test[3]]})\n",
    "print(results.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a sense of how well this plain vanilla MLP performs, below are the same performance metrics for a RUM-MNL model printed (on all data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LL\t\t -5761.741       \n",
      "LL0\t\t -8196.021       \n",
      "cross_entropy\t 0.823       \n",
      "rho_sq\t\t 0.297\n"
     ]
    }
   ],
   "source": [
    "print(f'LL\\t\\t {results_rum_mnl.getGeneralStatistics()[\"Final log likelihood\"][0]:0.3f} \\\n",
    "      \\nLL0\\t\\t {results_rum_mnl.getGeneralStatistics()[\"Null log likelihood\"][0]:0.3f} \\\n",
    "      \\ncross_entropy\\t {-results_rum_mnl.getGeneralStatistics()[\"Final log likelihood\"][0]/len(dff):0.3f} \\\n",
    "      \\nrho_sq\\t\\t {results_rum_mnl.getGeneralStatistics()[\"Rho-square for the null model\"][0]:0.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As can be seen, the model fit of the MLP is considerably higher than of the linear-additive RUM-MNL model.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ``Exercise 3: Does using more nodes improve the model performance?``\n",
    "`A` Calculate the number of weights consumed by the current MLP with 10 hidden nodes in 1 hidden layer. <br>\n",
    "`B` Retrain your model several times with {10,30,60,90} nodes. Report the cross-entropy performance on the train and test data sets.<br>\n",
    "`C` Does increasing the number of nodes lead to a lower cross-entropy on the train and or test set? What is happening?<br>\n",
    "`D` Suppose you would have many more choice observations from this survey. Would that enable you to develop a much better model with a cross entropy performance of say <0.10 (on the test set)? Explain your answer. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{green}{\\text{Add your answers here}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWERS\n",
    "# A)\n",
    "# B)\n",
    "# C)\n",
    "# D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `3. Using Early stopping to avoid overfitting`\n",
    "Early stopping refers to a technique that stops the training of the network when the performance on the test data set no longer improves. Thereby, early stopping avoids the model to overfit the data. It essetially stops the training before the model can overfit.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note this is the same 'plain vanilla' MLP, but now we set early_stopping = True\n",
    "# A validation_fraction is added. This fraction is the proportion of training data to set aside as validation set for early stopping. This data set is used to determine when to stop. \n",
    "# The training stops when the performance on the validation data set does not improve for n_iter_no_change in a row\n",
    "# We use the MLP with 10 nodes and one hidden layer again.\n",
    "layers = (10)\n",
    "n_iter_no_change = 10\n",
    "mlp_early_st = MLPClassifier(hidden_layer_sizes = layers, solver='adam', learning_rate_init = 0.001, alpha=0, batch_size=250, activation = 'relu', max_iter = 2000, early_stopping=True, n_iter_no_change = n_iter_no_change,validation_fraction = 0.25) \n",
    "\n",
    "# Train the MLP using the train data\n",
    "# Note that we use df.values here. This is due to a small bug in sk-learn. Without .values sk-learn still works, but prompts some warnings\n",
    "mlp_early_st.fit(X_train.values, Y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is good practice to look at the learning curve, to see how much the model has improved from the initial point,\n",
    "# and how it has evolved over the epochs.\n",
    "# The learning curve plot also illustrates well what early stopping does.\n",
    "fig, ax = plt.subplots(figsize = (10,5))\n",
    "plt.plot(mlp.loss_curve_,label=f'MLP with {mlp.hidden_layer_sizes} hidden nodes, WITHOUT early stopping')\n",
    "plt.plot(mlp_early_st.loss_curve_,label=f'MLP with {mlp_early_st.hidden_layer_sizes} hidden nodes, WITH early stopping')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Cross entropy loss')\n",
    "ax.grid(True,linewidth = 0.5)\n",
    "ax.set_ylim(0.0,1.2)\n",
    "ax.set_xlim(0,mlp.n_iter_)\n",
    "ax.set_title('Effect of early stopping')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's use our evaluation function again to evaluate performance of the MLP with early stopping on the training and test data set\n",
    "eval_train_early_st = eval_performance(mlp_early_st.predict_proba(X_train.values),np.transpose([Y_train ==1,Y_train ==2,Y_train ==3, Y_train ==4]), X_train[['av_car','av_bus','av_rail','av_air']])\n",
    "eval_test_early_st  = eval_performance(mlp_early_st.predict_proba(X_test.values), np.transpose([Y_test  ==1,Y_test  ==2,Y_test  ==3, Y_test  ==4]), X_test[['av_car','av_bus','av_rail','av_air']])\n",
    "\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "results_early_st = pd.DataFrame({'data set':     ['Train','Test'],\n",
    "                        'LL':           [eval_train_early_st[0], eval_test_early_st[0]],\n",
    "                        'LL0':          [eval_train_early_st[1], eval_test_early_st[1]],\n",
    "                        'cross_entropy':[eval_train_early_st[2], eval_test_early_st[2]],\n",
    "                        'rho_sq':       [eval_train_early_st[3], eval_test_early_st[3]]})\n",
    "print(results_early_st.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ``Exercise 4: Can we overfit with early stopping?``\n",
    "`A` Did early stopping reduced overfitting? How can you see this from the printed results?<br>\n",
    "`B` Try if early stoppping also helps to avoid overfitting when using more nodes, e.g. 100, or (50,50) nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{green}{\\text{Add your answers here}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWERS\n",
    "# A)\n",
    "# B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `4. Using k-fold cross validation to evaluate generalisation performance`\n",
    "k-fold cross validation is commonly used to more accurately **evaluate the generalisation performance** of a given network. It improves a simple train-test split approach in that it systematically cuts the data set in k pieces. k-fold cross validation is especially crucial when tuning hyperparameters (as we will see later)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create MLP object (plain vanilla MLP without early stopping)\n",
    "layers = 10\n",
    "mlp_cv = MLPClassifier(hidden_layer_sizes = layers, solver='adam', learning_rate_init = 0.001, alpha=0, batch_size=250, activation = 'relu', max_iter = 2000) \n",
    "\n",
    "# Create scoring function\n",
    "# It is necessary to create a scoring function when working with cross_validate of sk-learn\n",
    "# We set `greater_is_better` to `False` as we are minimising cross entropy loss\n",
    "logloss = make_scorer(log_loss, greater_is_better = False, needs_proba = True)\n",
    "\n",
    "# Apply cross_validate, using e.g. 5 folds\n",
    "# Since we use cross-validation training takes n_folds times longer than using a train-test split\n",
    "n_folds = 5\n",
    "cv_results = cross_validate(mlp_cv,dff_scaled[features],Y,cv = n_folds, scoring=logloss,return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the train and test performance in a bar plot, for each fold\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "x_axis = np.arange(n_folds)\n",
    "ax.bar(x_axis + -0.125, -cv_results['train_score'], color = 'b', width = 0.25,label = 'Train data set')\n",
    "ax.bar(x_axis +  0.125, -cv_results['test_score'], color = 'g', width = 0.25,label = 'Test data set')\n",
    "ax.set_xlabel('fold #')\n",
    "ax.set_ylabel('cross entropy')\n",
    "ax.grid()\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hence, this cross validation analysis supports the finding that a plain vanilla MLP (i.e. without early stopping) only slightly overfits the data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `5. Tuning hyperparameter`\n",
    "When training MLPs (and most other ML models) there are several parameters we can **'tune'** (optimise) to improve the model's performance. The process of doing this is called **hyperparameter tuning**. Hyperparameter tuning can be done manually, but that is unwieldy. The GridSearchCV function in `sk-learn` automates the hyperparemeter tuning process. When tuning the hyperparameters, it is mandatory to use a k-fold cross validation approach. Otherwise, there is a risk of overfitting on the test set *because* the parameters can be tweaked until the estimator performs optimally on the test data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not change these lines (they ensure the code runs fast enough on colab and local, by reducing the no. iterations for colab)\n",
    "try:\n",
    "    num_iters \n",
    "except NameError:\n",
    "    num_iters = 2000\n",
    "else:\n",
    "    num_iters = 250\n",
    "\n",
    "# Create MLP object (plain vanilla MLP)\n",
    "mlp_gs = MLPClassifier(activation = 'relu', solver='adam', batch_size=250, max_iter=num_iters)\n",
    "\n",
    "# Define the hyperparameter search space\n",
    "# 'hidden_layer_sizes' defines the number of nodes and layers\n",
    "# 'alpha' governs the L2 regularisation\n",
    "# 'learning_rate_init' governs the learning rate.\n",
    "hyperparameter_space = {\n",
    "    'hidden_layer_sizes': [(10),(10,10),(30,30)],\n",
    "    'alpha': [0,0.01,1],\n",
    "    'learning_rate_init': [0.01,0.001,0.0001]}\n",
    "\n",
    "# Create scoring function\n",
    "logloss = make_scorer(log_loss, greater_is_better = False, needs_proba = True)\n",
    "\n",
    "# Create the grid_search object, with using the MLP classifier\n",
    "folds = 5 # Number of cross validation splits\n",
    "mlp_gridsearch = GridSearchCV(mlp_gs, hyperparameter_space, n_jobs=-1, cv=folds,scoring = logloss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the training/gridsearch\n",
    "# Note that this is computationally expensive! \n",
    "# It may take up to 5 minutes, since 3 x 3 x 3 = 27 models need to be trained, each with 5 folds (=135)\n",
    "mlp_gridsearch.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save your hyperparameter tuning results, so we only have to do it once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your model \n",
    "filename = 'my_tuned_model.sav'\n",
    "pickle.dump(mlp_gridsearch, open(filename,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your model (if you have a saved model)\n",
    "# mlp_gridsearch = pickle.load(open(filename,'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualise the hyperparameter tuning results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect results into a new pandas dataframe\n",
    "df_gridsearch = pd.DataFrame.from_dict(mlp_gridsearch.cv_results_)\n",
    "    \n",
    "# Add new column with a label for the hyperparameter combinations %% NOT SURE IF THIS IS BET WAY TO DO THIS IN PYTHON   \n",
    "df_gridsearch['gs_combinations'] = 'L2 = '+ df_gridsearch['param_alpha'].astype('str') + '; Learning_rate = '+ df_gridsearch['param_learning_rate_init'].astype('str') + '; Layers = ' + df_gridsearch['param_hidden_layer_sizes'].astype('str')\n",
    "df_gridsearch = df_gridsearch.sort_values('rank_test_score')\n",
    "\n",
    "# Visualise deviation in performance across hyper parameter settings\n",
    "plt.figure(figsize = (16,6))\n",
    "ax = sns.barplot(x = df_gridsearch.gs_combinations,y=-df_gridsearch.mean_test_score,palette=\"Blues_d\",)\n",
    "ax.set_ylim(0.6,1.2)\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "print('Best hyperparameters found:\\t', mlp_gridsearch.best_params_)\n",
    "print('Best model performance:\\t\\t', -mlp_gridsearch.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ``Exercise 5: Hyperparameter tuning``\n",
    "`A` Compare the performance of the hypertuned model with the plain vanilla MLP. Has the generalisation performance improved? How much?<br>\n",
    "`B` What hyperparameter turns out to be particularly impactful on the model performance?<br>\n",
    "`C` Can you think of reasons why this could be the case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{green}{\\text{Add your answers here}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWERS\n",
    "# A)\n",
    "# B)\n",
    "# C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(Re)Training the model with optimised hyperparameters**<br> \n",
    "After completing hypertuning, you know the optimal hyperparameters. <br>\n",
    "Therefore, after hypertuning we always retrain the model using the optimised hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new mlp object using the optimised hyperparameters, just using the train/test split\n",
    "layers = mlp_gridsearch.best_params_['hidden_layer_sizes']\n",
    "lr = mlp_gridsearch.best_params_['learning_rate_init']\n",
    "alpha = mlp_gridsearch.best_params_['alpha']\n",
    "mlp_gs = MLPClassifier(hidden_layer_sizes = layers, solver='adam', learning_rate_init = lr, alpha=alpha, batch_size=250, activation = 'tanh', max_iter = 2000) \n",
    "\n",
    "# Train the model\n",
    "mlp_gs.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's also evaluate performance on the hypertuned model using our evaluation function\n",
    "# Note we use the full data here\n",
    "eval_gridsearch = eval_performance(mlp_gs.predict_proba(dff_scaled[features]),np.transpose([Y ==1,Y ==2,Y ==3, Y==4]), dff_scaled[['av_car','av_bus','av_rail','av_air']])\n",
    "\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "results_clf = pd.DataFrame({'data set': ['All data'],\n",
    "                        'LL':           [eval_gridsearch[0]],\n",
    "                        'LL0':          [eval_gridsearch[1]],\n",
    "                        'cross_entropy':[eval_gridsearch[2]],\n",
    "                        'rho_sq':       [eval_gridsearch[3]]})\n",
    "print(results_clf.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `6. Evaluating and comparing performances across trained models`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the performance of a wide range is metrics are available, beyond generalisation performance.<br>\n",
    "Here, we look at:<br>\n",
    "i. Confusion matrix<br>\n",
    "ii. Precision, Recall, and F1-score<br>\n",
    "iii. Matthew's correlation coefficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**i) Confusion matrix**<br>\n",
    "Confusion matrices shows counts from predicted and actual outcomes. The counts on the diagonal are correctly classified outcomes (the model predictions and the ground true are the same). The counts on the off diagonal elements are the misclassified outcomes. Hence, the best classifier will have a confusion matrix with only diagonal elements and the rest of the elements set to zero.<br>\n",
    "We compare the **MLP with early stopping** against the **MLP with hyperparameter tuning**.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the choices for the test data set, using the MLP trained with early stopping and MLP with hyperparameters tuned\n",
    "Y_pred_early_st  = mlp_early_st.predict(X_test.values)  # 0/1 predictions of MLP trained with early stopping\n",
    "Y_pred_gs = mlp_gs.predict(X_test)                      # 0/1 predictions of MLP with hyperparameters tuned\n",
    "\n",
    "# Show the confusion matrices, to compare the hyperparameter tuned network with the early stopping network\n",
    "fig, ax = plt.subplots(2,2,figsize = (16,12))\n",
    "fig.set_tight_layout(True)\n",
    "ylabels = ['Car', 'Bus', 'Rail', 'Air']\n",
    "cm1 = ConfusionMatrixDisplay.from_predictions(y_true=Y_test,y_pred=Y_pred_early_st, display_labels = ylabels, normalize=None,  ax=ax[(0,0)])\n",
    "cm2 = ConfusionMatrixDisplay.from_predictions(y_true=Y_test,y_pred=Y_pred_early_st, display_labels = ylabels, normalize='true',ax=ax[(1,0)])\n",
    "cm3 = ConfusionMatrixDisplay.from_predictions(y_true=Y_test,y_pred=Y_pred_gs, display_labels = ylabels, normalize=None,  ax=ax[(0,1)])\n",
    "cm4 = ConfusionMatrixDisplay.from_predictions(y_true=Y_test,y_pred=Y_pred_gs, display_labels = ylabels, normalize='true',ax=ax[(1,1)])\n",
    "\n",
    "# Add titles\n",
    "cm1.ax_.set_title(f'MLP with {mlp_early_st.hidden_layer_sizes} nodes \\n trained with early stopping')\n",
    "cm2.ax_.set_title(f'MLP with {mlp_early_st.hidden_layer_sizes} nodes \\n trained with early stopping')\n",
    "cm3.ax_.set_title(f'MLP with {mlp_gs.hidden_layer_sizes} nodes \\n hyperparameters tuned')\n",
    "cm4.ax_.set_title(f'MLP with {mlp_gs.hidden_layer_sizes} nodes \\n hyperparameters tuned')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ``Exercise 6: Model accuracy``\n",
    "Accuracy is defined as the true positives over the total number of cases.<br>\n",
    "`A` Manually compute the prediction accuracy of the model with early stopping and the model with hyperparameter tuning<br>\n",
    "`B` For which class (Train/SM/Car) does the hyperparameter tuning improves the prediction accuracy most?<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{green}{\\text{Add your answers here}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWERS\n",
    "# A)\n",
    "# B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ii) Precision, Recall, and F1**<br>\n",
    "Looking at the confusion matrices, the improvements in prediction accuracy due to the hyperparameter tuning may not seem very impressive. However, one should keep in mind that 0/1 predictions are sensitive to class imbalances, which are present in these data. Moreover, accuracy can be a misleading metric for imbalanced data sets. A naive model that would simply always predict \"SM\" will already do quite good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To assess the model performance in more depth, we thus must look at the predictions at the level of the classes.<br> \n",
    "Next, we compute Precision, Recall, and F1 score.<br>\n",
    "* **Precision** Tells you what fraction of predictions for a given class are actually of that class.<br>\n",
    "* **Recall** Tells what fraction of all observations belonging to a given class are correctly predicted as such by the model. Recall is also known as True Positive Rate (TPR), Sensitivity, Probability of Detection. <br>\n",
    "* **F1 score** combines precision and recall into a single measure. Mathematically it’s the harmonic mean of precision and recall. It can be calculated as follows: <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To calculate the precision, recal and f1 score we conveniently use sk-learn's 'classification_report' functionality\n",
    "print('Classification report for plain vanilla MLP with early stopping\\n',classification_report(Y_test,Y_pred_early_st, target_names= ylabels))\n",
    "print('\\nClassification report for plain vanilla MLP with hyperparameters tuned\\n',classification_report(Y_test,Y_pred_gs, target_names= ylabels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**iii) Matthew's correlation coefficient**<br>\n",
    "Another commonly used metric to evaluate the prediction performance while accounting for imbalances in the data set is  matthews correlation coefficient. Matthews Correlation Coefficient (MCC) is generally regarded as being one of the best measures to describe the confusion matrix of true and false positives and negatives by a **single number**, even if the classes are of very different sizes. The MCC is in essence a correlation coefficient value between -1 and +1. A coefficient of +1 represents a perfect prediction, 0 an average random prediction and -1 an inverse prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking into account the imbalances of the data\n",
    "print(f'Matthews correlation coefficient for plain Vanilla MLP with early stopping:\\t {matthews_corrcoef(Y_test, Y_pred_early_st):4.3f}')\n",
    "print(f'Matthews correlation coefficient for plain Vanilla MLP with hypertuning:\\t {matthews_corrcoef(Y_test, Y_pred_gs):4.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ``Exercise 7: Model precision, recall, f1 and Matthew's correlation coefficent``\n",
    "`A` Compare and interpret the results from the classifications reports between the early stopping and hypertuned model.<br>\n",
    "`B` Compare and interpret the results from Matthews correlation coefficient between the early stopping and hypertuned model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{green}{\\text{Add your answers here}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWERS\n",
    "# A)\n",
    "# B)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 64-bit ('py37')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "52edd5821628e65ed257fae09420cd5b7ee9f38a64f5e5ba5a5e47a3545ddf85"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
